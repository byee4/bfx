{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the dpsi from the average of the psi values for each replicate - average dpsi for its matched control.\n",
    "- maybe just use the RMATS outputs from xintao instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from rnaseq import rmats_inclevel_analysis as rmats\n",
    "import os\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_reps_and_return_dpsi(psi_val_file_dict):\n",
    "    \"\"\"\n",
    "    given a dictionary of:\n",
    "    control_rep1, control_rep2, expt_rep1, expt_rep2:\n",
    "    \n",
    "    Return the full pipeline:\n",
    "    1. read dpsi\n",
    "    2. get average psi for each rep\n",
    "    3. dpsi by subtracting expt minus control\n",
    "    \"\"\"\n",
    "    progress = tnrange(7, desc='outer loop', leave=False)\n",
    "    control_rep1_df = read_psi(psi_val_file_dict['control_rep1'])\n",
    "    progress.update(1)\n",
    "    control_rep2_df = read_psi(psi_val_file_dict['control_rep2'])\n",
    "    progress.update(1)\n",
    "    expt_rep1_df = read_psi(psi_val_file_dict['expt_rep1'])\n",
    "    progress.update(1)\n",
    "    expt_rep2_df = read_psi(psi_val_file_dict['expt_rep2'])\n",
    "    progress.update(1)\n",
    "    control_df = get_avg_psi(control_rep1_df, control_rep2_df, 'control')\n",
    "    progress.update(1)\n",
    "    expt_df = get_avg_psi(expt_rep1_df, expt_rep2_df, 'expt')\n",
    "    progress.update(1)\n",
    "    dpsi = get_dpsi(control_df, expt_df)\n",
    "    progress.update(1)\n",
    "    return dpsi\n",
    "\n",
    "DFHEAD = ['bam', 'psi', 'jxc', 'exon']\n",
    "\n",
    "def read_psi(f):\n",
    "    \"\"\"\n",
    "    Reads in a file generated from a hack of eric's script:\n",
    "    see (in the 'from_eric/' folder):\n",
    "    calculate_psi_for_gencode_exons_manifest2_justpsi_flip_loop.pl\n",
    "    \"\"\"\n",
    "    df = pd.read_table(f, names=DFHEAD)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    if not df.shape[0] == df.drop_duplicates('exon').shape[0]: # assures there are unique exon triplets for each file\n",
    "        print(df.duplicated().head())\n",
    "        print(\"Warning: {} has multiple exon triplets for a single jxc region\".format(f))    \n",
    "    return df\n",
    "\n",
    "def get_avg_psi(df_rep1, df_rep2, prefix='control'):\n",
    "    \"\"\"\n",
    "    get average psi from two dataframes. \n",
    "    Fills nonexistant exons (do not meet min threshold of 30 reads?) with 0\n",
    "    \"\"\"\n",
    "    df_rep1.columns = [\n",
    "        '{}_rep1bam'.format(prefix), \n",
    "        '{}_rep1psi'.format(prefix), \n",
    "        '{}_rep1jxc'.format(prefix), \n",
    "        'exon'\n",
    "    ]\n",
    "    df_rep2.columns = [\n",
    "        '{}_rep2bam'.format(prefix), \n",
    "        '{}_rep2psi'.format(prefix), \n",
    "        '{}_rep2jxc'.format(prefix), \n",
    "        'exon'\n",
    "    ]\n",
    "    \n",
    "    ### \n",
    "    # merges the rep1 and rep2 dpsi and calculates average psi \n",
    "    # exons that are calculated one but not the other are 0\n",
    "    # by means of an outer join on the middle exon\n",
    "    ### \n",
    "    merged = pd.merge(df_rep1, df_rep2, how='outer', on='exon') \n",
    "    merged = merged.fillna(0)\n",
    "    \n",
    "    merged['{}_avg_psi'.format(prefix)] = (\n",
    "        merged['{}_rep1psi'.format(prefix)] + \\\n",
    "        merged['{}_rep2psi'.format(prefix)])/2\n",
    "    return merged\n",
    "\n",
    "def get_dpsi(control_df, expt_df):\n",
    "    \"\"\"\n",
    "    control - knockdown expt\n",
    "    (-) more included in knockdown expt\n",
    "    (+) more included in control\n",
    "    This function is experimental centric. \n",
    "    So any average psi that is in the control vs not in expt will not be counted?\n",
    "    \n",
    "    This function also sets the middle exon, which may be the same for\n",
    "    two different triplet events. Therefore may produce identical exons for\n",
    "    distinct triplets and different dpsi values for a single middle exon.\n",
    "    \n",
    "    SEE: prioritize duplicates and drop function, keep only lowest dpsi\n",
    "    \"\"\"\n",
    "    progress = tnrange(7, desc='get dpsi', leave=False)\n",
    "    merged = pd.merge(expt_df, control_df, how='left', on='exon').fillna(0)\n",
    "    progress.update(1)\n",
    "    merged['dpsi'] = merged['control_avg_psi'] - merged['expt_avg_psi']\n",
    "    progress.update(1)\n",
    "    merged['middle_exon_start'] = merged['exon'].apply(lambda x: x.split('|')[1].split('-')[0])\n",
    "    progress.update(1)\n",
    "    merged['middle_exon_end'] = merged['exon'].apply(lambda x: x.split('|')[1].split('-')[1])\n",
    "    progress.update(1)\n",
    "    merged['chrom'] = merged.apply(get_chrom, axis=1)\n",
    "    progress.update(1)\n",
    "    merged['strand'] = merged.apply(get_strand, axis=1)\n",
    "    progress.update(1)\n",
    "    merged = merged[['chrom', 'middle_exon_start', 'middle_exon_end', 'dpsi', 'strand']]\n",
    "    progress.update(1)\n",
    "    return merged\n",
    "\n",
    "def get_strand(row):\n",
    "    \"\"\"\n",
    "    given chrom:strand:upstream:middle:downstream format\n",
    "    of the jxc field, return the strand\n",
    "    \"\"\"\n",
    "    if row['expt_rep1jxc'] != 0:\n",
    "        return row['expt_rep1jxc'].split(':')[1]\n",
    "    elif row['expt_rep2jxc'] != 0:\n",
    "        return row['expt_rep2jxc'].split(':')[1]\n",
    "    else:\n",
    "        print(row)\n",
    "        return 0\n",
    "    \n",
    "def get_chrom(row):\n",
    "    \"\"\"\n",
    "    given chrom:strand:upstream:middle:downstream format\n",
    "    of the jxc field, return the chrom\n",
    "    \"\"\"\n",
    "    if row['expt_rep1jxc'] != 0:\n",
    "        return row['expt_rep1jxc'].split(':')[0]\n",
    "    elif row['expt_rep2jxc'] != 0:\n",
    "        return row['expt_rep2jxc'].split(':')[0]\n",
    "    else:\n",
    "        print(row)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rep_and_control(manifest_file, rbp_name):\n",
    "    \"\"\"\n",
    "    given a manifest file name and an RBP name, \n",
    "    return the associated BAM files for control and expt (rep1 and 2).\n",
    "    \"\"\"\n",
    "    df = pd.read_table(manifest, index_col='name')\n",
    "    return {\n",
    "        'control_rep1':df.ix[rbp_name]['control_rep1'],\n",
    "        'control_rep2':df.ix[rbp_name]['control_rep2'],\n",
    "        'expt_rep1':df.ix[rbp_name]['expt_rep1'],\n",
    "        'expt_rep2':df.ix[rbp_name]['expt_rep2'],\n",
    "    }\n",
    "\n",
    "def get_psi_value_files(manifest_file, psi_dir, rbp_name):\n",
    "    \"\"\"\n",
    "    given a psi value directory and an RBP name,\n",
    "    return the associated psi value files for control and expt (rep1 and 2).\n",
    "    \"\"\"\n",
    "    psi_value_files = {}\n",
    "    bam_files = get_rep_and_control(manifest_file, rbp_name)\n",
    "    for key, bam_file in bam_files.iteritems():\n",
    "        psi_value_files[key] = os.path.join(psi_dir, bam_file.replace('.bam','.txt'))\n",
    "    return psi_value_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manifest = '/projects/ps-yeolab3/encode/hepg2_brenton-graveley_ambiguous_bams_for_integrated_analysis.txt'\n",
    "psi_dir = '/projects/ps-yeolab3/bay001/tmp/psi/'\n",
    "out_dir = '/projects/ps-yeolab3/bay001/tmp/dpsi_0/'\n",
    "psi_vals = glob.glob(os.path.join(psi_dir, \"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rbfox2 = get_psi_value_files(manifest, psi_dir, 'RBFOX2')\n",
    "df = get_reps_and_return_dpsi(rbfox2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manifest_df = pd.read_table(manifest)\n",
    "all_rbps = manifest_df['name']\n",
    "progress = tnrange(len(all_rbps))\n",
    "for name in all_rbps:\n",
    "    files = get_psi_value_files(manifest, psi_dir, name)\n",
    "    df = get_reps_and_return_dpsi(files)\n",
    "    # df.set_index(['chrom','middle_exon_start','middle_exon_end','strand'], inplace=True)\n",
    "    df.to_csv(os.path.join(out_dir, '{}.txt'.format(name)), sep='\\t', header=False)\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Join dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/ps-yeolab3/bay001/tmp/dpsi_0/SRFBP1.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dpsi_dir = '/projects/ps-yeolab3/bay001/tmp/dpsi_0/'\n",
    "dpsi_files = glob.glob(os.path.join(out_dir, '*.txt'))\n",
    "dpsi_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_index(row):\n",
    "    return \"{}:{}:{}:{}\".format(row['chrom'], row['start'], row['end'], row['strand'])\n",
    "\n",
    "def set_index_and_remove_cols(df):\n",
    "    del df['old_idx']\n",
    "    df['new_idx'] = df.apply(concat_index, axis=1)\n",
    "    del df['chrom']\n",
    "    del df['start']\n",
    "    del df['end']\n",
    "    del df['strand']\n",
    "    df.set_index('new_idx', inplace=True)\n",
    "    return df\n",
    "\n",
    "def prioritize_duplicates_and_remove(df):\n",
    "    # remove all dpsi of 0\n",
    "    df = df[df['dpsi'] != 0]\n",
    "    # sort remaining dpsi by ascending order\n",
    "    df.sort_values(by=['dpsi'], inplace=True, ascending=True)\n",
    "    # report the first only (lowest dpsi) for any duplicated exon\n",
    "    df.drop_duplicates(['chrom','start','end','strand'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n",
      "/home/bay001/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "DPSI_FILE_HEADER = ['old_idx','chrom','start','end','dpsi','strand']\n",
    "\n",
    "\n",
    "def join_all_dpsi_values(dpsi_files, cell_type):\n",
    "    \"\"\"\n",
    "    joins all of the dpsi values into a single merged table\n",
    "    \"\"\"\n",
    "    progress = tnrange(len(dpsi_files))\n",
    "    \n",
    "    # initialize first one\n",
    "    merged = pd.read_table(dpsi_files[0], names=DPSI_FILE_HEADER) #, index_col=[1,2,3,5])\n",
    "    merged = prioritize_duplicates_and_remove(merged)\n",
    "    merged = set_index_and_remove_cols(merged)\n",
    "    # rename columns to match the rbp\n",
    "    merged.columns = [os.path.basename(dpsi_files[0]).replace('.txt','_{}'.format(cell_type))]\n",
    "    progress.update(1)\n",
    "    # Merge the other rbps\n",
    "    for dpsi_file in dpsi_files[1:]:\n",
    "        \n",
    "        # read in file\n",
    "        df = pd.read_table(dpsi_file, names=DPSI_FILE_HEADER) #, index_col=[1,2,3,5])\n",
    "        df = prioritize_duplicates_and_remove(df)\n",
    "        df = set_index_and_remove_cols(df)\n",
    "        df.columns = [os.path.basename(dpsi_file).replace('.txt','_{}'.format(cell_type))]\n",
    "        \n",
    "        merged = pd.merge(merged, df, how='outer', left_index=True, right_index=True)\n",
    "        # print(merged.ix[merged.duplicated()].head())\n",
    "        # merged.drop_duplicates(inplace=True)\n",
    "        progress.update(1)\n",
    "    return merged\n",
    "\n",
    "merged = join_all_dpsi_values(dpsi_files, 'HepG2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.to_csv(os.path.join(dpsi_dir, 'MERGED_DPSI.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use merged dataframe to create trackhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t},\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def format_df_to_trackhub(df, qcat_dict, out_file):\n",
    "    \"\"\"\n",
    "    kind of a messy way to re-format the dataframe\n",
    "    \"\"\"\n",
    "    o = open(out_file, 'w')\n",
    "    count = 0\n",
    "    progress = tnrange(df.shape[0])\n",
    "    for col, row in df.iterrows():\n",
    "        row_str = \"{}\\t{}\\t{}\\t\".format(row['chrom'], row['start'], row['end'])\n",
    "        row_str = row_str + 'id:{},qcat:'.format(count)\n",
    "        qcat_str = \"\"\n",
    "        for i in row.index:\n",
    "            if i in qcat_dict.keys() and not pd.isnull(row[i]): # there is a value\n",
    "                qcat_str = qcat_str + '[{},{}], '.format(qcat_dict[i][0], row[i])\n",
    "                \n",
    "        qcat_str = qcat_str[:-2]\n",
    "        \n",
    "        o.write(row_str + '[ {} ]\\n'.format(qcat_str))\n",
    "        count += 1\n",
    "        progress.update(1)\n",
    "    o.close()\n",
    "    return 0\n",
    "\n",
    "def rbp_to_qcat(json_like):\n",
    "    \"\"\"\n",
    "    turns this json like file into a dictionary\n",
    "    with rbp names as keys and category ID, color as values\n",
    "    \"\"\"\n",
    "    categories = defaultdict(list)\n",
    "    with open(json_like, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('\\t'):\n",
    "                try:\n",
    "                    line = line.replace('\\'','')\n",
    "                    category, rbp = line.replace('[','').replace(']','').split(':')\n",
    "                    rbpname, rbpcolor, _ = rbp.split(',')\n",
    "                    categories[rbpname] = [int(category.replace('\\t','')), rbpcolor]\n",
    "                except ValueError:\n",
    "                    print(line)\n",
    "    return categories\n",
    "\n",
    "def return_json_id_from_merged_column(column):\n",
    "    \"\"\"\n",
    "    only difference between this and jxc function in the junctioncountsonly notebook is the - and _\n",
    "    \"\"\"\n",
    "    rbp_name, rbp_cell = column.split('_')\n",
    "    return \"{}_{}_01\".format(rbp_name, rbp_cell) # we don't care about replicates; rmats is one file per 2 reps\n",
    "\n",
    "def merged_column_to_qcat_elements(column, qcat_dict):\n",
    "    count = len(qcat_dict.keys())\n",
    "    # print(return_json_id_from_merged_column(column))\n",
    "    values = qcat_dict[\n",
    "        return_json_id_from_merged_column(column)\n",
    "    ]\n",
    "    if values != []:\n",
    "        return values, count\n",
    "    else:\n",
    "        return [count+1, \"#0000FF\"], count+1 # default blue\n",
    "    \n",
    "json_file = '/home/bay001/projects/encode/analysis/rnaseq_trackhub/combined_10bpfull.datahub.pos'\n",
    "qcat_dict = rbp_to_qcat(json_file)\n",
    "# format_df_to_trackhub(trunc, '/home/bay001/test.bed') # .to_csv('/home/bay001/test.bed', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_file = '/projects/ps-yeolab3/bay001/tmp/dpsi_0/TRACKHUB.ALL'\n",
    "merged_reset_idx = merged.reset_index()\n",
    "merged_reset_idx['chrom'] = merged_reset_idx['new_idx'].apply(lambda x: x.split(':')[0])\n",
    "merged_reset_idx['start'] = merged_reset_idx['new_idx'].apply(lambda x: x.split(':')[1])\n",
    "merged_reset_idx['end'] = merged_reset_idx['new_idx'].apply(lambda x: x.split(':')[2])\n",
    "\n",
    "# format_df_to_trackhub(merged_reset_idx, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this ensures that a unique identifier will be assigned to any shRNA rnaseq expt not already assigned in clip data.\n",
    "new_qcat_dict = {}\n",
    "count = len(qcat_dict)\n",
    "for column in merged_reset_idx.columns:\n",
    "    \n",
    "    if 'HepG2' in column:\n",
    "        qcat_id_color, count = merged_column_to_qcat_elements(column, qcat_dict)\n",
    "        new_qcat_dict[column] = [qcat_id_color[0], qcat_id_color[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_df_to_trackhub(merged_reset_idx, new_qcat_dict, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write datahub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AARS_HepG2': [499, '#0000FF'],\n",
       " 'AATF_HepG2': [382, '#0000FF'],\n",
       " 'ABCF1_HepG2': [496, '#0000FF'],\n",
       " 'ACO1_HepG2': [504, '#0000FF'],\n",
       " 'ADAR_HepG2': [500, '#0000FF'],\n",
       " 'AGO1_HepG2': [425, '#0000FF'],\n",
       " 'AKAP1_HepG2': [414, '#0000FF'],\n",
       " 'AKAP8L_HepG2': [392, '#0000FF'],\n",
       " 'AKAP8_HepG2': [416, '#0000FF'],\n",
       " 'APOBEC3C_HepG2': [369, '#0000FF'],\n",
       " 'ASCC1_HepG2': [495, '#0000FF'],\n",
       " 'ATP5C1_HepG2': [374, '#0000FF'],\n",
       " 'AUH_HepG2': [75, '#4A3B53'],\n",
       " 'BCCIP_HepG2': [33, '#8FB0FF'],\n",
       " 'BCLAF1_HepG2': [395, '#0000FF'],\n",
       " 'BOP1_HepG2': [245, '#6367A9'],\n",
       " 'BUD13_HepG2': [215, '#C8A1A1'],\n",
       " 'CALR_HepG2': [372, '#0000FF'],\n",
       " 'CCAR1_HepG2': [480, '#0000FF'],\n",
       " 'CCAR2_HepG2': [389, '#0000FF'],\n",
       " 'CDC40_HepG2': [247, '#549E79'],\n",
       " 'CEBPZ_HepG2': [428, '#0000FF'],\n",
       " 'CELF1_HepG2': [479, '#0000FF'],\n",
       " 'CIRBP_HepG2': [403, '#0000FF'],\n",
       " 'CKAP4_HepG2': [384, '#0000FF'],\n",
       " 'CNOT7_HepG2': [376, '#0000FF'],\n",
       " 'CPSF6_HepG2': [373, '#0000FF'],\n",
       " 'CPSF7_HepG2': [408, '#0000FF'],\n",
       " 'CSTF2T_HepG2': [87, '#FF90C9'],\n",
       " 'CSTF2_HepG2': [323, '#DA007C'],\n",
       " 'DAZAP1_HepG2': [485, '#0000FF'],\n",
       " 'DDX19B_HepG2': [501, '#0000FF'],\n",
       " 'DDX1_HepG2': [433, '#0000FF'],\n",
       " 'DDX21_HepG2': [453, '#0000FF'],\n",
       " 'DDX24_HepG2': [390, '#0000FF'],\n",
       " 'DDX27_HepG2': [484, '#0000FF'],\n",
       " 'DDX28_HepG2': [446, '#0000FF'],\n",
       " 'DDX3X_HepG2': [209, '#001E09'],\n",
       " 'DDX47_HepG2': [380, '#0000FF'],\n",
       " 'DDX52_HepG2': [492, '#0000FF'],\n",
       " 'DDX55_HepG2': [275, '#404E55'],\n",
       " 'DDX59_HepG2': [255, '#201625'],\n",
       " 'DDX5_HepG2': [454, '#0000FF'],\n",
       " 'DDX6_HepG2': [293, '#5B4534'],\n",
       " 'DHX30_HepG2': [337, '#5B4E51'],\n",
       " 'DKC1_HepG2': [239, '#D790FF'],\n",
       " 'DNAJC21_HepG2': [461, '#0000FF'],\n",
       " 'DNAJC2_HepG2': [410, '#0000FF'],\n",
       " 'DROSHA_HepG2': [325, '#8CD0FF'],\n",
       " 'EEF2_HepG2': [489, '#0000FF'],\n",
       " 'EFTUD2_HepG2': [311, '#FDE8DC'],\n",
       " 'EIF2S1_HepG2': [486, '#0000FF'],\n",
       " 'EIF2S2_HepG2': [383, '#0000FF'],\n",
       " 'EIF3D_HepG2': [285, '#6A3A4C'],\n",
       " 'EIF3G_HepG2': [437, '#0000FF'],\n",
       " 'EIF4A3_HepG2': [385, '#0000FF'],\n",
       " 'EIF4B_HepG2': [287, '#83AB58'],\n",
       " 'EIF4G1_HepG2': [406, '#0000FF'],\n",
       " 'EIF4G2_HepG2': [465, '#0000FF'],\n",
       " 'ESF1_HepG2': [436, '#0000FF'],\n",
       " 'ETF1_HepG2': [449, '#0000FF'],\n",
       " 'EWSR1_HepG2': [396, '#0000FF'],\n",
       " 'EXOSC9_HepG2': [476, '#0000FF'],\n",
       " 'FAM120A_HepG2': [89, '#D16100'],\n",
       " 'FASTKD1_HepG2': [411, '#0000FF'],\n",
       " 'FASTKD2_HepG2': [331, '#636375'],\n",
       " 'FIP1L1_HepG2': [415, '#0000FF'],\n",
       " 'FKBP4_HepG2': [23, '#0000A6'],\n",
       " 'FMR1_HepG2': [378, '#0000FF'],\n",
       " 'FTO_HepG2': [429, '#0000FF'],\n",
       " 'FUBP3_HepG2': [321, '#66796D'],\n",
       " 'FUS_HepG2': [371, '#0000FF'],\n",
       " 'FXR1_HepG2': [386, '#0000FF'],\n",
       " 'G3BP1_HepG2': [375, '#0000FF'],\n",
       " 'G3BP2_HepG2': [509, '#0000FF'],\n",
       " 'GEMIN5_HepG2': [503, '#0000FF'],\n",
       " 'GNB2L1_HepG2': [407, '#0000FF'],\n",
       " 'GPKOW_HepG2': [493, '#0000FF'],\n",
       " 'GRSF1_HepG2': [277, '#0089A3'],\n",
       " 'GRWD1_HepG2': [289, '#001C1E'],\n",
       " 'GTF2F1_HepG2': [149, '#CC0744'],\n",
       " 'HDGF_HepG2': [364, '#0000FF'],\n",
       " 'HLTF_HepG2': [432, '#0000FF'],\n",
       " 'HNRNPA0_HepG2': [370, '#0000FF'],\n",
       " 'HNRNPA1_HepG2': [81, '#FF2F80'],\n",
       " 'HNRNPA2B1_HepG2': [398, '#0000FF'],\n",
       " 'HNRNPAB_HepG2': [497, '#0000FF'],\n",
       " 'HNRNPC_HepG2': [1, '#000000'],\n",
       " 'HNRNPD_HepG2': [474, '#0000FF'],\n",
       " 'HNRNPF_HepG2': [377, '#0000FF'],\n",
       " 'HNRNPK_HepG2': [7, '#FF34FF'],\n",
       " 'HNRNPLL_HepG2': [438, '#0000FF'],\n",
       " 'HNRNPL_HepG2': [349, '#FFF69F'],\n",
       " 'HNRNPM_HepG2': [21, '#7A4900'],\n",
       " 'HNRNPUL1_HepG2': [105, '#DDEFFF'],\n",
       " 'HNRNPU_HepG2': [77, '#61615A'],\n",
       " 'HSPD1_HepG2': [512, '#0000FF'],\n",
       " 'IGF2BP1_HepG2': [5, '#1CE6FF'],\n",
       " 'IGF2BP2_HepG2': [455, '#0000FF'],\n",
       " 'IGF2BP3_HepG2': [11, '#008941'],\n",
       " 'ILF2_HepG2': [478, '#0000FF'],\n",
       " 'ILF3_HepG2': [319, '#372101'],\n",
       " 'KHDRBS1_HepG2': [483, '#0000FF'],\n",
       " 'KHSRP_HepG2': [507, '#0000FF'],\n",
       " 'KIF1C_HepG2': [445, '#0000FF'],\n",
       " 'KRR1_HepG2': [506, '#0000FF'],\n",
       " 'LARP4_HepG2': [249, '#A3C8C9'],\n",
       " 'LARP7_HepG2': [91, '#1B4400'],\n",
       " 'LIN28B_HepG2': [151, '#0AA6D8'],\n",
       " 'LSM11_HepG2': [273, '#34362D'],\n",
       " 'MAGOH_HepG2': [439, '#0000FF'],\n",
       " 'MARK2_HepG2': [391, '#0000FF'],\n",
       " 'MATR3_HepG2': [359, '#D0AC94'],\n",
       " 'METAP2_HepG2': [464, '#0000FF'],\n",
       " 'MSI2_HepG2': [457, '#0000FF'],\n",
       " 'MTPAP_HepG2': [490, '#0000FF'],\n",
       " 'NAA15_HepG2': [475, '#0000FF'],\n",
       " 'NCBP2_HepG2': [197, '#B05B6F'],\n",
       " 'NELFE_HepG2': [387, '#0000FF'],\n",
       " 'NIP7_HepG2': [456, '#0000FF'],\n",
       " 'NKRF_HepG2': [241, '#9B9700'],\n",
       " 'NOL12_HepG2': [233, '#772600'],\n",
       " 'NONO_HepG2': [491, '#0000FF'],\n",
       " 'NPM1_HepG2': [511, '#0000FF'],\n",
       " 'NSUN2_HepG2': [447, '#0000FF'],\n",
       " 'NUFIP2_HepG2': [419, '#0000FF'],\n",
       " 'NUP35_HepG2': [388, '#0000FF'],\n",
       " 'NUSAP1_HepG2': [368, '#0000FF'],\n",
       " 'PA2G4_HepG2': [412, '#0000FF'],\n",
       " 'PABPC1_HepG2': [397, '#0000FF'],\n",
       " 'PABPC4_HepG2': [444, '#0000FF'],\n",
       " 'PARN_HepG2': [508, '#0000FF'],\n",
       " 'PCBP1_HepG2': [487, '#0000FF'],\n",
       " 'PCBP2_HepG2': [127, '#C2FF99'],\n",
       " 'PES1_HepG2': [394, '#0000FF'],\n",
       " 'PHF6_HepG2': [400, '#0000FF'],\n",
       " 'PKM_HepG2': [409, '#0000FF'],\n",
       " 'PNPT1_HepG2': [365, '#0000FF'],\n",
       " 'PPIG_HepG2': [213, '#04F757'],\n",
       " 'PPIL4_HepG2': [462, '#0000FF'],\n",
       " 'PRPF6_HepG2': [510, '#0000FF'],\n",
       " 'PRPF8_HepG2': [85, '#B903AA'],\n",
       " 'PSIP1_HepG2': [441, '#0000FF'],\n",
       " 'PTBP1_HepG2': [361, '#7A87A1'],\n",
       " 'PUF60_HepG2': [434, '#0000FF'],\n",
       " 'PUM1_HepG2': [367, '#0000FF'],\n",
       " 'PUM2_HepG2': [502, '#0000FF'],\n",
       " 'PUS1_HepG2': [463, '#0000FF'],\n",
       " 'QKI_HepG2': [199, '#575329'],\n",
       " 'RAVER1_HepG2': [427, '#0000FF'],\n",
       " 'RBFOX2_HepG2': [3, '#FFFF00'],\n",
       " 'RBM15_HepG2': [243, '#A77500'],\n",
       " 'RBM17_HepG2': [514, '#0000FF'],\n",
       " 'RBM22_HepG2': [211, '#013349'],\n",
       " 'RBM25_HepG2': [505, '#0000FF'],\n",
       " 'RBM27_HepG2': [417, '#0000FF'],\n",
       " 'RBM34_HepG2': [498, '#0000FF'],\n",
       " 'RBM39_HepG2': [393, '#0000FF'],\n",
       " 'RBM47_HepG2': [442, '#0000FF'],\n",
       " 'RBM5_HepG2': [259, '#BC23FF'],\n",
       " 'RCC2_HepG2': [426, '#0000FF'],\n",
       " 'RECQL_HepG2': [468, '#0000FF'],\n",
       " 'RPL23A_HepG2': [351, '#66E1D3'],\n",
       " 'RPLP0_HepG2': [404, '#0000FF'],\n",
       " 'RPS10_HepG2': [458, '#0000FF'],\n",
       " 'RPS19_HepG2': [466, '#0000FF'],\n",
       " 'RPS2_HepG2': [481, '#0000FF'],\n",
       " 'RPS3A_HepG2': [418, '#0000FF'],\n",
       " 'RPS5_HepG2': [341, '#922329'],\n",
       " 'RRP9_HepG2': [451, '#0000FF'],\n",
       " 'RTF1_HepG2': [443, '#0000FF'],\n",
       " 'SAFB2_HepG2': [472, '#0000FF'],\n",
       " 'SART3_HepG2': [435, '#0000FF'],\n",
       " 'SBDS_HepG2': [469, '#0000FF'],\n",
       " 'SERBP1_HepG2': [401, '#0000FF'],\n",
       " 'SF1_HepG2': [477, '#0000FF'],\n",
       " 'SF3A3_HepG2': [155, '#788D66'],\n",
       " 'SF3B1_HepG2': [460, '#0000FF'],\n",
       " 'SF3B4_HepG2': [31, '#004D43'],\n",
       " 'SFPQ_HepG2': [167, '#BEC459'],\n",
       " 'SLBP_HepG2': [488, '#0000FF'],\n",
       " 'SLTM_HepG2': [29, '#B79762'],\n",
       " 'SMN1_HepG2': [402, '#0000FF'],\n",
       " 'SMNDC1_HepG2': [125, '#C0B9B2'],\n",
       " 'SND1_HepG2': [95, '#7B4F4B'],\n",
       " 'SNRNP200_HepG2': [424, '#0000FF'],\n",
       " 'SNRNP70_HepG2': [399, '#0000FF'],\n",
       " 'SRFBP1_HepG2': [363, '#0000FF'],\n",
       " 'SRP68_HepG2': [423, '#0000FF'],\n",
       " 'SRSF1_HepG2': [93, '#000035'],\n",
       " 'SRSF3_HepG2': [452, '#0000FF'],\n",
       " 'SRSF5_HepG2': [482, '#0000FF'],\n",
       " 'SRSF7_HepG2': [9, '#FF4A46'],\n",
       " 'SRSF9_HepG2': [15, '#A30059'],\n",
       " 'SSB_HepG2': [381, '#0000FF'],\n",
       " 'SSRP1_HepG2': [420, '#0000FF'],\n",
       " 'STAU1_HepG2': [421, '#0000FF'],\n",
       " 'STIP1_HepG2': [448, '#0000FF'],\n",
       " 'SUB1_HepG2': [329, '#FF1A59'],\n",
       " 'SUCLG1_HepG2': [450, '#0000FF'],\n",
       " 'SUGP2_HepG2': [335, '#1E0200'],\n",
       " 'SUPT6H_HepG2': [513, '#0000FF'],\n",
       " 'SUPV3L1_HepG2': [333, '#8ADBB4'],\n",
       " 'TAF15_HepG2': [153, '#FFB500'],\n",
       " 'TARDBP_HepG2': [459, '#0000FF'],\n",
       " 'TBRG4_HepG2': [281, '#A4E804'],\n",
       " 'TFIP11_HepG2': [494, '#0000FF'],\n",
       " 'TIA1_HepG2': [13, '#006FA6'],\n",
       " 'TIAL1_HepG2': [431, '#0000FF'],\n",
       " 'TRA2A_HepG2': [17, '#FFDBE5'],\n",
       " 'TRIM56_HepG2': [422, '#0000FF'],\n",
       " 'TROVE2_HepG2': [261, '#B4A8BD'],\n",
       " 'TUFM_HepG2': [379, '#0000FF'],\n",
       " 'U2AF1_HepG2': [79, '#4FC601'],\n",
       " 'U2AF2_HepG2': [67, '#FEFFE6'],\n",
       " 'UBE2L3_HepG2': [473, '#0000FF'],\n",
       " 'UCHL5_HepG2': [309, '#BF5650'],\n",
       " 'UPF1_HepG2': [471, '#0000FF'],\n",
       " 'UPF2_HepG2': [413, '#0000FF'],\n",
       " 'UTP18_HepG2': [430, '#0000FF'],\n",
       " 'UTP3_HepG2': [366, '#0000FF'],\n",
       " 'XPO5_HepG2': [339, '#C895C5'],\n",
       " 'XRCC5_HepG2': [440, '#0000FF'],\n",
       " 'XRCC6_HepG2': [97, '#A1C299'],\n",
       " 'XRN2_HepG2': [313, '#3B5DFF'],\n",
       " 'YBX3_HepG2': [467, '#0000FF'],\n",
       " 'ZNF622_HepG2': [405, '#0000FF'],\n",
       " 'ZRANB2_HepG2': [470, '#0000FF']}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_qcat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datahub_file = '/projects/ps-yeolab3/bay001/tmp/dpsi_0/DATAHUB'\n",
    "with open(datahub_file, 'w') as f:\n",
    "    f.write('[\\n')\n",
    "    f.write('{\\n')\n",
    "    f.write('type:\\'quantitativeCategorySeries\\',\\n')\n",
    "    f.write('name:\\'test_hub_please_ignore\\',\\n')\n",
    "    f.write('height:500,\\n')\n",
    "    f.write('url:\\\"https://google.com\\\",\\n')\n",
    "    f.write('backgroundcolor:\\'#FFFFFF,\\n')\n",
    "    f.write('mode:\\'show\\',\\n')\n",
    "    f.write('categories:{\\n')\n",
    "    ### write the actual stuff\n",
    "    for rbp_name, values in new_qcat_dict.iteritems():\n",
    "        f.write('\\t\\'{}\\':[\\'{}\\',\\'{}\\']\\n'.format(\n",
    "            values[0], rbp_name, values[1]\n",
    "            ))\n",
    "    f.write('\\t},\\n')\n",
    "    f.write('},\\n')\n",
    "    f.write(']')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "4957607a27c74999ae95dbd270464ba6": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "4a9ba064f8b04f8dbefb52696044bcbc": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "898ab91c97da4b86b7a9b25d671fa789": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
