{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper notebook for submitting the RBP maps script to TSCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import glob\n",
    "# import rethinkdb as r\n",
    "from collections import defaultdict\n",
    "from qtools import Submitter\n",
    "from encode import manifest_helpers as m\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "pd.set_option(\"display.max_colwidth\", 10000)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_runner = '/home/bay001/projects/codebase/rbp-maps/maps/plot_map.py'\n",
    "peak_runner = '/home/bay001/projects/codebase/rbp-maps/maps/plot_map.py'\n",
    "\n",
    "annotation_dir = '/projects/ps-yeolab3/bay001/maps/current_annotations/se'\n",
    "control_annotation_dir = '/projects/ps-yeolab3/bay001/maps/current_annotations/erics_controls/nonredundant_renamed/se/'\n",
    "\n",
    "params = {\n",
    "    'whole_read':{\n",
    "        'output_dir' : '/projects/ps-yeolab3/bay001/maps/current/se',\n",
    "        'clip_manifest' : '/projects/ps-yeolab3/bay001/reference_data/ENCODE/ENCODE_FINAL_ANNOTATIONS.uidsonly.txt.manifest.txt',\n",
    "        'prefix' : 'whole_read',\n",
    "        'website_manifest' : '/home/bay001/projects/maps_20160420/permanent_data/ALLDATASETS_submittedonly.website.wholeread.txt'\n",
    "    },\n",
    "    '5p':{\n",
    "        'output_dir' : '/projects/ps-yeolab3/bay001/maps/current/se_5p/',\n",
    "        'clip_manifest' : '/home/bay001/projects/maps_20160420/permanent_data/ALLDATASETS_submittedonly.5p.txt',\n",
    "        'prefix' : '5p',\n",
    "        'website_manifest' : '/home/bay001/projects/maps_20160420/permanent_data/ALLDATASETS_submittedonly.website.5p.txt'\n",
    "    },\n",
    "    'peak_bb':{\n",
    "        'output_dir' : '/projects/ps-yeolab3/bay001/maps/current/se_peak/',\n",
    "        'clip_manifest' : '/projects/ps-yeolab3/bay001/reference_data/ENCODE/ENCODE_FINAL_ANNOTATIONS.uidsonly.txt.manifest.txt',\n",
    "        'prefix' : 'peak',\n",
    "        'peak_dir' : '/projects/ps-yeolab3/bay001/maps/current_annotations/se_peak_bigbeds/'\n",
    "    },\n",
    "    'idr_bb':{\n",
    "        'output_dir':'/home/bay001/scratch/maps/se/idr/',\n",
    "        # 'output_dir' : '/projects/ps-yeolab3/bay001/maps/current/se_idr_peak/',\n",
    "        'clip_manifest' : '/projects/ps-yeolab3/bay001/reference_data/ENCODE/ENCODE_FINAL_ANNOTATIONS.uidsonly.txt.manifest.txt',\n",
    "        'prefix' : 'peak',\n",
    "        'peak_dir' : '/projects/ps-yeolab3/bay001/maps/current_annotations/se_peak_idr_bigbeds'\n",
    "    },\n",
    "    'whole_read_xcompare':{\n",
    "        'output_dir' : '/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/',\n",
    "        # 'output_dir' : '/projects/ps-yeolab3/bay001/maps/current/se_xcompare',\n",
    "        'clip_manifest' : '/projects/ps-yeolab3/bay001/reference_data/ENCODE/ENCODE_FINAL_ANNOTATIONS.uidsonly.txt.manifest.txt',\n",
    "        'prefix' : 'whole_read_xcompare',\n",
    "        'website_manifest' : '/home/bay001/projects/maps_20160420/permanent_data/ALLDATASETS_submittedonly.website.wholeread.txt'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define manifests, directories, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory `/projects/ps-yeolab3/bay001/maps/bash_scripts/12-3-2018': File exists\r\n"
     ]
    }
   ],
   "source": [
    "current_date = '12-3-2018'\n",
    "bash_scripts_dir = '/projects/ps-yeolab3/bay001/maps/bash_scripts/{}'.format(current_date)\n",
    "! mkdir $bash_scripts_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper scripts for accessing/joining RNASEQ and eCLIP annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 43)\n"
     ]
    }
   ],
   "source": [
    "read_type = 'whole_read'\n",
    "\n",
    "clip_df = pd.read_table(params[read_type]['clip_manifest'], sep='\\t')\n",
    "\n",
    "master_table = pd.read_table(\n",
    "    '/projects/ps-yeolab3/encode/rnaseq/eCLIP_finalstatus_20180406_ENCODE_combined_RNASEQ.tsv'\n",
    ")\n",
    "del master_table['eCLIP_Antibody_Lot_#']  # there is a NaN value in here that's screwing things up. Don't care about antibody anyway, so delete\n",
    "merged = pd.merge(\n",
    "    clip_df,\n",
    "    master_table,\n",
    "    how='right',\n",
    "    left_on=['uID'],\n",
    "    right_on=['eCLIP_Final_internal_accession']\n",
    ")\n",
    "merged.dropna(subset=['eCLIP_Final_internal_accession','SE_jxc_file'], inplace=True)\n",
    "print(merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>RBP</th>\n",
       "      <th>Cellline</th>\n",
       "      <th>CLIP_rep1</th>\n",
       "      <th>CLIP_rep2</th>\n",
       "      <th>INPUT</th>\n",
       "      <th>eCLIP_uID</th>\n",
       "      <th>eCLIP_Official_Gene_Symbol</th>\n",
       "      <th>eCLIP_Final_internal_accession</th>\n",
       "      <th>eCLIP_Submission_status</th>\n",
       "      <th>eCLIP_Antibody_Cat_#</th>\n",
       "      <th>eCLIP_Cell_Line</th>\n",
       "      <th>RNASEQ_Experiment_ID</th>\n",
       "      <th>RNASEQ_RBP</th>\n",
       "      <th>RNASEQ_Official_RBP</th>\n",
       "      <th>RNASEQ_Cell_line</th>\n",
       "      <th>RNASEQ_Control_Experiment_ID</th>\n",
       "      <th>CONTROL_RBP</th>\n",
       "      <th>CONTROL_Cell_line</th>\n",
       "      <th>RNASEQ_Replicate_rep1</th>\n",
       "      <th>RNASEQ_FASTQ_R1_rep1</th>\n",
       "      <th>RNASEQ_FASTQ_R2_rep1</th>\n",
       "      <th>RNASEQ_BAM_rep1</th>\n",
       "      <th>RNASEQ_TSV_rep1</th>\n",
       "      <th>Rep_rep1</th>\n",
       "      <th>CONTROL_Replicate_rep1</th>\n",
       "      <th>CONTROL_FASTQ_R1_rep1</th>\n",
       "      <th>CONTROL_FASTQ_R2_rep1</th>\n",
       "      <th>CONTROL_BAM_rep1</th>\n",
       "      <th>CONTROL_TSV_rep1</th>\n",
       "      <th>RNASEQ_Replicate_rep2</th>\n",
       "      <th>RNASEQ_FASTQ_R1_rep2</th>\n",
       "      <th>RNASEQ_FASTQ_R2_rep2</th>\n",
       "      <th>RNASEQ_BAM_rep2</th>\n",
       "      <th>RNASEQ_TSV_rep2</th>\n",
       "      <th>Rep_rep2</th>\n",
       "      <th>CONTROL_Replicate_rep2</th>\n",
       "      <th>CONTROL_FASTQ_R1_rep2</th>\n",
       "      <th>CONTROL_FASTQ_R2_rep2</th>\n",
       "      <th>CONTROL_BAM_rep2</th>\n",
       "      <th>CONTROL_TSV_rep2</th>\n",
       "      <th>SE_jxc_file</th>\n",
       "      <th>RNASEQ_DESeq2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>RBFOX2</td>\n",
       "      <td>HepG2</td>\n",
       "      <td>/projects/ps-yeolab3/encode/analysis/encode_master/204_01_RBFOX2.merged.r2.bam</td>\n",
       "      <td>/projects/ps-yeolab3/encode/analysis/encode_master/204_02_RBFOX2.merged.r2.bam</td>\n",
       "      <td>/projects/ps-yeolab3/encode/analysis/encode_master/RBFOX2-204-INPUT_S2_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.bam</td>\n",
       "      <td>204.0</td>\n",
       "      <td>RBFOX2</td>\n",
       "      <td>204</td>\n",
       "      <td>DONE - 2 reps submitted 6/28/15</td>\n",
       "      <td>A300-864A</td>\n",
       "      <td>HepG2</td>\n",
       "      <td>ENCSR767LLP</td>\n",
       "      <td>RBFOX2</td>\n",
       "      <td>RBFOX2</td>\n",
       "      <td>HepG2</td>\n",
       "      <td>ENCSR104ABF</td>\n",
       "      <td>non-target</td>\n",
       "      <td>HepG2</td>\n",
       "      <td>RBFOX2_BGHLV26_35</td>\n",
       "      <td>ENCFF201PEI</td>\n",
       "      <td>ENCFF508QNI</td>\n",
       "      <td>ENCFF347ERZ</td>\n",
       "      <td>ENCFF222JWL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>non-target_BGHLV26-1</td>\n",
       "      <td>ENCFF291QQH</td>\n",
       "      <td>ENCFF602GIQ</td>\n",
       "      <td>ENCFF988VWE</td>\n",
       "      <td>ENCFF653XRX</td>\n",
       "      <td>RBFOX2_BGHLV26_36</td>\n",
       "      <td>ENCFF040CTS</td>\n",
       "      <td>ENCFF435HLB</td>\n",
       "      <td>ENCFF946VPZ</td>\n",
       "      <td>ENCFF042VXF</td>\n",
       "      <td>2.0</td>\n",
       "      <td>non-target_BGHLV26-2</td>\n",
       "      <td>ENCFF503VRZ</td>\n",
       "      <td>ENCFF105YHI</td>\n",
       "      <td>ENCFF893QHC</td>\n",
       "      <td>ENCFF401ECA</td>\n",
       "      <td>RBFOX2-BGHLV26-HepG2.set26.SE.MATS.JunctionCountOnly.txt</td>\n",
       "      <td>HepG2_RBFOX2_BGHLV26_DESeq_output.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uID     RBP Cellline  \\\n",
       "1  204  RBFOX2    HepG2   \n",
       "\n",
       "                                                                        CLIP_rep1  \\\n",
       "1  /projects/ps-yeolab3/encode/analysis/encode_master/204_01_RBFOX2.merged.r2.bam   \n",
       "\n",
       "                                                                        CLIP_rep2  \\\n",
       "1  /projects/ps-yeolab3/encode/analysis/encode_master/204_02_RBFOX2.merged.r2.bam   \n",
       "\n",
       "                                                                                                                               INPUT  \\\n",
       "1  /projects/ps-yeolab3/encode/analysis/encode_master/RBFOX2-204-INPUT_S2_R1.unassigned.adapterTrim.round2.rmRep.rmDup.sorted.r2.bam   \n",
       "\n",
       "   eCLIP_uID eCLIP_Official_Gene_Symbol eCLIP_Final_internal_accession  \\\n",
       "1      204.0                     RBFOX2                            204   \n",
       "\n",
       "             eCLIP_Submission_status eCLIP_Antibody_Cat_# eCLIP_Cell_Line  \\\n",
       "1  DONE - 2 reps submitted 6/28/15              A300-864A           HepG2   \n",
       "\n",
       "  RNASEQ_Experiment_ID RNASEQ_RBP RNASEQ_Official_RBP RNASEQ_Cell_line  \\\n",
       "1          ENCSR767LLP     RBFOX2              RBFOX2            HepG2   \n",
       "\n",
       "  RNASEQ_Control_Experiment_ID CONTROL_RBP CONTROL_Cell_line  \\\n",
       "1                  ENCSR104ABF  non-target             HepG2   \n",
       "\n",
       "  RNASEQ_Replicate_rep1 RNASEQ_FASTQ_R1_rep1 RNASEQ_FASTQ_R2_rep1  \\\n",
       "1     RBFOX2_BGHLV26_35          ENCFF201PEI          ENCFF508QNI   \n",
       "\n",
       "  RNASEQ_BAM_rep1 RNASEQ_TSV_rep1  Rep_rep1 CONTROL_Replicate_rep1  \\\n",
       "1     ENCFF347ERZ     ENCFF222JWL       1.0   non-target_BGHLV26-1   \n",
       "\n",
       "  CONTROL_FASTQ_R1_rep1 CONTROL_FASTQ_R2_rep1 CONTROL_BAM_rep1  \\\n",
       "1           ENCFF291QQH           ENCFF602GIQ      ENCFF988VWE   \n",
       "\n",
       "  CONTROL_TSV_rep1 RNASEQ_Replicate_rep2 RNASEQ_FASTQ_R1_rep2  \\\n",
       "1      ENCFF653XRX     RBFOX2_BGHLV26_36          ENCFF040CTS   \n",
       "\n",
       "  RNASEQ_FASTQ_R2_rep2 RNASEQ_BAM_rep2 RNASEQ_TSV_rep2  Rep_rep2  \\\n",
       "1          ENCFF435HLB     ENCFF946VPZ     ENCFF042VXF       2.0   \n",
       "\n",
       "  CONTROL_Replicate_rep2 CONTROL_FASTQ_R1_rep2 CONTROL_FASTQ_R2_rep2  \\\n",
       "1   non-target_BGHLV26-2           ENCFF503VRZ           ENCFF105YHI   \n",
       "\n",
       "  CONTROL_BAM_rep2 CONTROL_TSV_rep2  \\\n",
       "1      ENCFF893QHC      ENCFF401ECA   \n",
       "\n",
       "                                                SE_jxc_file  \\\n",
       "1  RBFOX2-BGHLV26-HepG2.set26.SE.MATS.JunctionCountOnly.txt   \n",
       "\n",
       "                           RNASEQ_DESeq2  \n",
       "1  HepG2_RBFOX2_BGHLV26_DESeq_output.txt  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[merged['uID']=='204']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot SE Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/projects/ps-yeolab3/bay001/maps/current_annotations/se/RBFOX2-BGHLV26-HepG2.set26-included-upon-knockdown',\n",
       " '/projects/ps-yeolab3/bay001/maps/current_annotations/se/RBFOX2-BGHLV26-HepG2.set26-excluded-upon-knockdown')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_clip_file_from_uid(uid, df=merged):\n",
    "    df = df[df['uID']==uid]\n",
    "    return df['CLIP_rep1'].values[0], \\\n",
    "            df['CLIP_rep2'].values[0], \\\n",
    "            df['INPUT'].values[0], \\\n",
    "            df['eCLIP_Official_Gene_Symbol'].values[0], \\\n",
    "            df['eCLIP_Cell_Line'].values[0], \\\n",
    "            df['SE_jxc_file'].values[0]\n",
    "\n",
    "r1, r2, i, rbp, cell, jxc_se  = get_clip_file_from_uid('204')\n",
    "\n",
    "def get_annotations_from_jxc_se(jxc, jxc_dir=annotation_dir):\n",
    "    \"\"\" jxc contains the basename of the junction counts file \"\"\"\n",
    "    orig_file = os.path.join(jxc_dir, jxc)\n",
    "    positive = os.path.splitext(orig_file)[0] + \".positive.nr.txt\"\n",
    "    positive = positive.replace('.SE.MATS.JunctionCountOnly.positive.nr.txt','-included-upon-knockdown')\n",
    "    negative = os.path.splitext(orig_file)[0] + \".negative.nr.txt\"\n",
    "    negative = negative.replace('.SE.MATS.JunctionCountOnly.negative.nr.txt','-excluded-upon-knockdown')\n",
    "    assert os.path.exists(orig_file)\n",
    "    if not os.path.exists(positive):\n",
    "        positive = None\n",
    "    if not os.path.exists(negative):\n",
    "        negative = None\n",
    "    return positive, negative\n",
    "\n",
    "get_annotations_from_jxc_se(jxc_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning, these dont match: DROSHA, RNASEN50-BGKLV28-K562.set28-included-upon-knockdown, RNASEN50-BGKLV28-K562.set28-excluded-upon-knockdown\n",
      "warning, these dont match: YBX3, CSDA-BGKLV24-K562.set24-included-upon-knockdown, CSDA-BGKLV24-K562.set24-excluded-upon-knockdown\n",
      "warning, these dont match: YBX3, CSDA-BGHLV20-HepG2.set20-included-upon-knockdown, CSDA-BGHLV20-HepG2.set20-excluded-upon-knockdown\n",
      "uIDs for which we have an RNASEQ ID, but we don't have the splicing data yet: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing 386 tasks as an array-job.\n",
      "Wrote commands to /projects/ps-yeolab3/bay001/maps/bash_scripts/12-3-2018/whole_read-SE_NR_svg.4.sh.\n"
     ]
    }
   ],
   "source": [
    "img_extension = ['svg']\n",
    "pos_splicing_suffix = '-included-upon-knockdown'\n",
    "neg_splicing_suffix = '-excluded-upon-knockdown'\n",
    "\n",
    "if not os.path.exists(bash_scripts_dir):\n",
    "    ! mkdir $bash_scripts_dir\n",
    "\n",
    "read_type = 'whole_read'\n",
    "normalization_levels = [4]\n",
    "\n",
    "### Force override of maps\n",
    "force = True\n",
    "\n",
    "### DEFINE BACKGROUNDS (THESE ARE STATIC AND DON'T CHANGE) ###\n",
    "k562_background_ce = os.path.join(control_annotation_dir, 'K562_constitutive_exons')\n",
    "k562_background_nse_all = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_all')\n",
    "k562_background_nse_inc = os.path.join(control_annotation_dir, 'K562_natively_included_cassette_exons')\n",
    "k562_background_nse_exc = os.path.join(control_annotation_dir, 'K562_natively_excluded_cassette_exons')\n",
    "k562_background_nse_avg = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_avg')\n",
    "\n",
    "hepg2_background_ce = os.path.join(control_annotation_dir, 'HepG2_constitutive_exons')\n",
    "hepg2_background_nse_all = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_all')\n",
    "hepg2_background_nse_inc = os.path.join(control_annotation_dir, 'HepG2_natively_included_cassette_exons')\n",
    "hepg2_background_nse_exc = os.path.join(control_annotation_dir, 'HepG2_natively_excluded_cassette_exons')\n",
    "hepg2_background_nse_avg = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_avg')\n",
    "\n",
    "# no_rnaseq = [] # uIDs for which we don't have rna seq expt ids for\n",
    "no_rnaseq_yet = [] # uIDs for which we have an expt id, but haven't downloaded the data yet (or there were no significant splice events)\n",
    "cmds = []\n",
    "\n",
    "for normalization_level in normalization_levels:\n",
    "    for ext in img_extension:\n",
    "        for uid in merged['uID']:\n",
    "            r1, r2, i, rbp, cell, jxc_se = get_clip_file_from_uid(uid)\n",
    "\n",
    "            if cell == 'K562':\n",
    "                background1 = k562_background_ce\n",
    "                background2 = k562_background_nse_all\n",
    "                background3 = k562_background_nse_inc\n",
    "                background4 = k562_background_nse_exc\n",
    "                background5 = k562_background_nse_avg\n",
    "            elif cell == 'HepG2':\n",
    "                background1 = hepg2_background_ce\n",
    "                background2 = hepg2_background_nse_all\n",
    "                background3 = hepg2_background_nse_inc\n",
    "                background4 = hepg2_background_nse_exc\n",
    "                background5 = hepg2_background_nse_avg\n",
    "            else:\n",
    "                print(cell)\n",
    "\n",
    "\n",
    "            ##### get the positive and negative associated annotations using this prefix #####\n",
    "            positive, negative = get_annotations_from_jxc_se(\n",
    "                jxc_se\n",
    "            )\n",
    "            ### we HAVE to have at both positive and negative annotations to plot ###\n",
    "            if(positive == None or negative == None):\n",
    "                no_rnaseq_yet.append(uid)\n",
    "            else:\n",
    "                ### uses RBP name to ensure positive and negative annotations are being pulled ###\n",
    "                pos_prefix = os.path.basename(positive).split('-')[0]\n",
    "                neg_prefix = os.path.basename(negative).split('-')[0]\n",
    "                if not (pos_prefix in rbp and neg_prefix in rbp):\n",
    "                    print(\n",
    "                        'warning, these dont match: {}, {}, {}'.format(\n",
    "                            rbp, \n",
    "                            os.path.basename(positive),\n",
    "                            os.path.basename(negative)\n",
    "                        )\n",
    "                    )\n",
    "                ### Foreach replicate, build teh command used to call the python script.\n",
    "                for r in [r1, r2]:\n",
    "                    name = os.path.basename(r).replace('.bam','.{}.{}'.format(normalization_level, ext))\n",
    "                    output_filename = os.path.join(\n",
    "                        params[read_type]['output_dir'],\n",
    "                        name\n",
    "                    )\n",
    "\n",
    "                    # Build the cmd line\n",
    "                    cmd = \"python \" + density_runner\n",
    "                    cmd = cmd + \" --event {}\".format('se')\n",
    "                    cmd = cmd + \" --ipbam {}\".format(r)\n",
    "                    cmd = cmd + \" --inputbam {}\".format(i)\n",
    "                    cmd = cmd + \" --output {}\".format(output_filename)\n",
    "                    cmd = cmd + \" --annotations {} {} {} {} {} {} {}\".format(\n",
    "                        positive, negative, background1, background2, background3, background4, background5\n",
    "                    )\n",
    "                    cmd = cmd + \" --annotation_type {} {} {} {} {} {} {}\".format(\n",
    "                        'rmats', 'rmats', 'eric', 'eric', 'eric', 'eric', 'eric' \n",
    "                    )\n",
    "                    # cmd = cmd + \" --chrom_sizes {}\".format(chrom_sizes)\n",
    "                    cmd = cmd + \" --testnum {} {}\".format(0, 1)\n",
    "                    cmd = cmd + \" --bgnum {}\".format(3) # test against native SE\n",
    "                    cmd = cmd + \" --normalization_level {}\".format(normalization_level)\n",
    "                    cmd = cmd + \" --sigtest permutation\"\n",
    "                    if not os.path.exists(output_filename) or force == True:\n",
    "                        cmds.append(cmd)\n",
    "\n",
    "bash_script_sh = '/projects/ps-yeolab3/bay001/maps/bash_scripts/{}/{}-SE_NR_{}.{}.sh'.format(\n",
    "    current_date, \n",
    "    params[read_type]['prefix'], \n",
    "    ext,\n",
    "    normalization_level\n",
    ")\n",
    "\n",
    "Submitter(\n",
    "    cmds, \n",
    "    \"{}-SE_NR_{}\".format(params[read_type]['prefix'], ext), \n",
    "    sh=bash_script_sh,\n",
    "    submit=False,\n",
    "    array=True,\n",
    "    walltime='3:00:00',\n",
    "    queue='home-yeo'\n",
    ")\n",
    "\n",
    "### Print any missing/unavailable annotations to check over ###\n",
    "print(\"uIDs for which we have an RNASEQ ID, but we don't have the splicing data yet: {}\".format(\n",
    "        len(no_rnaseq_yet))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure we have made all of the maps we need for integrated paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = 'svg'\n",
    "for uid in merged['uID']:\n",
    "    r1, r2, i, rbp, cell, jxc_se = get_clip_file_from_uid(uid)\n",
    "    positive, negative = get_annotations_from_jxc_se(\n",
    "        jxc_se\n",
    "    )\n",
    "    if(positive == None or negative == None):\n",
    "        pass\n",
    "    else:\n",
    "        pdf = pd.read_table(positive)\n",
    "        ndf = pd.read_table(negative)\n",
    "\n",
    "        if(pdf.shape[0] >= 100 and ndf.shape[0] >= 100):\n",
    "            for r in [r1, r2]:\n",
    "                name = os.path.basename(r).replace('.bam','.{}.{}'.format(normalization_level, ext))\n",
    "                means = glob.glob(\n",
    "                    os.path.join(\n",
    "                        params[read_type]['output_dir'],\n",
    "                        os.path.basename(r).replace('.bam','*.means.txt')\n",
    "                    )\n",
    "                )\n",
    "                output_filename = os.path.join(\n",
    "                    params[read_type]['output_dir'],\n",
    "                    name\n",
    "                )\n",
    "                if not os.path.exists(output_filename):\n",
    "                    print(\"{} {} doesnt exist\".format(output_filename, jxc_se))\n",
    "                if len(means) != 7:\n",
    "                    print(\"missing means (found {})\".format(means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot SE Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'peak_bb'\n",
    "\n",
    "img_extensions = ['svg'] #,'svg']\n",
    "clip_df = pd.read_table(params[key]['clip_manifest'])\n",
    "\n",
    "no_rnaseq = [] # uIDs for which we don't have rna seq expt ids for\n",
    "no_rnaseq_yet = [] # uIDs for which we have an expt id, but haven't downloaded the data yet\n",
    "cmds = []\n",
    "force = True\n",
    "\n",
    "### DEFINE BACKGROUNDS (THESE ARE STATIC AND DON'T CHANGE) ###\n",
    "k562_background_ce = os.path.join(control_annotation_dir, 'K562_constitutive_exons')\n",
    "k562_background_nse_all = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_all')\n",
    "k562_background_nse_inc = os.path.join(control_annotation_dir, 'K562_natively_included_cassette_exons')\n",
    "k562_background_nse_exc = os.path.join(control_annotation_dir, 'K562_natively_excluded_cassette_exons')\n",
    "k562_background_nse_avg = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_avg')\n",
    "\n",
    "hepg2_background_ce = os.path.join(control_annotation_dir, 'HepG2_constitutive_exons')\n",
    "hepg2_background_nse_all = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_all')\n",
    "hepg2_background_nse_inc = os.path.join(control_annotation_dir, 'HepG2_natively_included_cassette_exons')\n",
    "hepg2_background_nse_exc = os.path.join(control_annotation_dir, 'HepG2_natively_excluded_cassette_exons')\n",
    "hepg2_background_nse_avg = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_avg')\n",
    "\n",
    "\n",
    "for ext in img_extensions:\n",
    "    for uid in merged['uID']:\n",
    "        peak_files = glob.glob(os.path.join(\n",
    "            params[key]['peak_dir'], \n",
    "            '{}_0*.basedon_{}_0*.peaks.l2inputnormnew.bed.compressed.bed.p3f3.bed.sorted.bed.bb'.format(\n",
    "                uid, uid\n",
    "            )\n",
    "        ))\n",
    "        assert len(peak_files) == 2\n",
    "        \n",
    "        for peak in peak_files:\n",
    "            output_filename = os.path.join(\n",
    "                params[key]['output_dir'],\n",
    "                os.path.basename(peak).replace('.bb','.bb.{}'.format(ext))\n",
    "            )\n",
    "            r1, r2, i, rbp, cell, jxc_se = get_clip_file_from_uid(uid)\n",
    "\n",
    "\n",
    "            if cell == 'K562':\n",
    "                background1 = k562_background_ce\n",
    "                background2 = k562_background_nse_all\n",
    "                background3 = k562_background_nse_inc\n",
    "                background4 = k562_background_nse_exc\n",
    "                background5 = k562_background_nse_avg\n",
    "            elif cell == 'HepG2':\n",
    "                background1 = hepg2_background_ce\n",
    "                background2 = hepg2_background_nse_all\n",
    "                background3 = hepg2_background_nse_inc\n",
    "                background4 = hepg2_background_nse_exc\n",
    "                background5 = hepg2_background_nse_avg\n",
    "            else:\n",
    "                print(cell)\n",
    "\n",
    "            ##### get the positive and negative associated annotations using this prefix #####\n",
    "            positive, negative = get_annotations_from_jxc_se(\n",
    "                jxc_se\n",
    "            )\n",
    "            if uid == '560':\n",
    "                print(positive, negative)\n",
    "            if(positive == None or negative == None):\n",
    "                no_rnaseq_yet.append(uid)\n",
    "            else:\n",
    "                # Build the cmd line\n",
    "                cmd = \"python \" + peak_runner\n",
    "                cmd = cmd + \" --event {}\".format('se')\n",
    "                cmd = cmd + \" --peak {}\".format(peak)\n",
    "                cmd = cmd + \" --output {}\".format(output_filename)\n",
    "                cmd = cmd + \" --annotations {} {} {} {} {} {} {}\".format(\n",
    "                    positive, negative, background1, background2, background3, background4, background5\n",
    "                )\n",
    "                cmd = cmd + \" --annotation_type {} {} {} {} {} {} {}\".format(\n",
    "                    'rmats', 'rmats', 'eric', 'eric', 'eric', 'eric', 'eric' \n",
    "                )\n",
    "                # cmd = cmd + \" --chrom_sizes {}\".format(chrom_sizes)\n",
    "                cmd = cmd + \" --testnum {} {}\".format(0, 1)\n",
    "                cmd = cmd + \" --bgnum {}\".format(3) # test against native SE\n",
    "                cmd = cmd + \" --normalization_level {}\".format(0)\n",
    "                cmd = cmd + \" --sigtest {}\".format(\"fisher\")\n",
    "                if not os.path.exists(output_filename) or force == True:\n",
    "                    cmds.append(cmd)\n",
    "\n",
    "bash_script_sh = '/projects/ps-yeolab3/bay001/maps/bash_scripts/{}/SE_PEAK_PNGS.sh'.format(current_date)\n",
    "\n",
    "Submitter(\n",
    "    cmds, \n",
    "    \"SE_PEAK_PNGS\", \n",
    "    sh=bash_script_sh,\n",
    "    submit=False,\n",
    "    array=True,\n",
    "    walltime='0:20:00',\n",
    "    queue='home-yeo'\n",
    ")\n",
    "\n",
    "with open(bash_script_sh.replace('.sh','.missing.txt'), 'w') as o:\n",
    "    for no in no_rnaseq:\n",
    "        o.write(\n",
    "            '{}\\t{}\\n'.format(\n",
    "                m.get_clip_file_from_uid(clip_df, no)[3],\n",
    "                m.get_clip_file_from_uid(clip_df, no)[4],\n",
    "            )\n",
    "        )\n",
    "    print(\"\\n\\nNO SUFFICIENT POSITIVE OR NEGATIVE SIGNIFICANT ANNOTATIONS:\")\n",
    "    for no in no_rnaseq_yet:\n",
    "        print(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDR peak splice maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'idr_bb'\n",
    "\n",
    "img_extensions = ['svg'] #,'svg']\n",
    "clip_df = pd.read_table(params[key]['clip_manifest'])\n",
    "\n",
    "no_rnaseq = [] # uIDs for which we don't have rna seq expt ids for\n",
    "no_rnaseq_yet = [] # uIDs for which we have an expt id, but haven't downloaded the data yet\n",
    "cmds = []\n",
    "force = False\n",
    "\n",
    "### DEFINE BACKGROUNDS (THESE ARE STATIC AND DON'T CHANGE) ###\n",
    "k562_background_ce = os.path.join(control_annotation_dir, 'K562_constitutive_exons')\n",
    "k562_background_nse_all = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_all')\n",
    "k562_background_nse_inc = os.path.join(control_annotation_dir, 'K562_natively_included_cassette_exons')\n",
    "k562_background_nse_exc = os.path.join(control_annotation_dir, 'K562_natively_excluded_cassette_exons')\n",
    "k562_background_nse_avg = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_avg')\n",
    "\n",
    "hepg2_background_ce = os.path.join(control_annotation_dir, 'HepG2_constitutive_exons')\n",
    "hepg2_background_nse_all = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_all')\n",
    "hepg2_background_nse_inc = os.path.join(control_annotation_dir, 'HepG2_natively_included_cassette_exons')\n",
    "hepg2_background_nse_exc = os.path.join(control_annotation_dir, 'HepG2_natively_excluded_cassette_exons')\n",
    "hepg2_background_nse_avg = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_avg')\n",
    "\n",
    "\n",
    "for ext in img_extensions:\n",
    "    for uid in merged['uID']:\n",
    "        peak_files = glob.glob(os.path.join(\n",
    "            params[key]['peak_dir'], \n",
    "            '{}.01v02.IDR.out.0102merged.bed.blacklist_removed.bed.p0f0.bed.sorted.bed.bb'.format(\n",
    "                uid\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        assert len(peak_files) == 1\n",
    "        \n",
    "        for peak in peak_files:\n",
    "            output_filename = os.path.join(\n",
    "                params[key]['output_dir'],\n",
    "                os.path.basename(peak).replace('.bb','.bb.{}'.format(ext))\n",
    "            )\n",
    "            r1, r2, i, rbp, cell, jxc_se = get_clip_file_from_uid(uid)\n",
    "\n",
    "\n",
    "            if cell == 'K562':\n",
    "                background1 = k562_background_ce\n",
    "                background2 = k562_background_nse_all\n",
    "                background3 = k562_background_nse_inc\n",
    "                background4 = k562_background_nse_exc\n",
    "                background5 = k562_background_nse_avg\n",
    "            elif cell == 'HepG2':\n",
    "                background1 = hepg2_background_ce\n",
    "                background2 = hepg2_background_nse_all\n",
    "                background3 = hepg2_background_nse_inc\n",
    "                background4 = hepg2_background_nse_exc\n",
    "                background5 = hepg2_background_nse_avg\n",
    "            else:\n",
    "                print(cell)\n",
    "\n",
    "            ##### get the positive and negative associated annotations using this prefix #####\n",
    "            positive, negative = get_annotations_from_jxc_se(\n",
    "                jxc_se\n",
    "            )\n",
    "            if uid == '678':\n",
    "                print(positive, negative)\n",
    "            if(positive == None or negative == None):\n",
    "                no_rnaseq_yet.append(uid)\n",
    "            else:\n",
    "                # Build the cmd line\n",
    "                cmd = \"python \" + peak_runner\n",
    "                cmd = cmd + \" --event {}\".format('se')\n",
    "                cmd = cmd + \" --peak {}\".format(peak)\n",
    "                cmd = cmd + \" --output {}\".format(output_filename)\n",
    "                cmd = cmd + \" --annotations {} {} {} {} {} {} {}\".format(\n",
    "                    positive, negative, background1, background2, background3, background4, background5\n",
    "                )\n",
    "                cmd = cmd + \" --annotation_type {} {} {} {} {} {} {}\".format(\n",
    "                    'rmats', 'rmats', 'eric', 'eric', 'eric', 'eric', 'eric' \n",
    "                )\n",
    "                # cmd = cmd + \" --chrom_sizes {}\".format(chrom_sizes)\n",
    "                cmd = cmd + \" --testnum {} {}\".format(0, 1)\n",
    "                cmd = cmd + \" --bgnum {}\".format(3) # test against native SE\n",
    "                cmd = cmd + \" --normalization_level {}\".format(0)\n",
    "                cmd = cmd + \" --sigtest {}\".format(\"fisher\")\n",
    "                cmd = cmd + \" --confidence 1\"\n",
    "                if not os.path.exists(output_filename) or force == True:\n",
    "                    cmds.append(cmd)\n",
    "\n",
    "bash_script_sh = '/projects/ps-yeolab3/bay001/maps/bash_scripts/{}/SE_IDR_PNGS.sh'.format(current_date)\n",
    "\n",
    "Submitter(\n",
    "    cmds, \n",
    "    \"SE_IDR_SVGS\", \n",
    "    sh=bash_script_sh,\n",
    "    submit=False,\n",
    "    array=True,\n",
    "    walltime='0:20:00',\n",
    "    queue='home-yeo'\n",
    ")\n",
    "\n",
    "with open(bash_script_sh.replace('.sh','.missing.txt'), 'w') as o:\n",
    "    for no in no_rnaseq:\n",
    "        o.write(\n",
    "            '{}\\t{}\\n'.format(\n",
    "                m.get_clip_file_from_uid(clip_df, no)[3],\n",
    "                m.get_clip_file_from_uid(clip_df, no)[4],\n",
    "            )\n",
    "        )\n",
    "    print(\"\\n\\nNO SUFFICIENT POSITIVE OR NEGATIVE SIGNIFICANT ANNOTATIONS:\")\n",
    "    for no in no_rnaseq_yet:\n",
    "        print(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RBPclasses\n",
    "- This file contains all RBPs, not just the ones we clipped, and not just the ones with RNA SEQ. Be aware that some of these RBPs have not been clipped, and thus will not be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class#</th>\n",
       "      <th>Class ID</th>\n",
       "      <th>SubmittedDueToFamily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SND1-HepG2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FXR1-K562</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SND1-K562</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FXR2-HepG2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G3BP1-HepG2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Class# Class ID  SubmittedDueToFamily\n",
       "0   SND1-HepG2       1      CDS                     1\n",
       "1    FXR1-K562       1      CDS                     1\n",
       "2    SND1-K562       1      CDS                     1\n",
       "3   FXR2-HepG2       1      CDS                     1\n",
       "4  G3BP1-HepG2       1      CDS                     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = pd.read_table(\n",
    "    \"/projects/ps-yeolab3/bay001/reference_data/ENCODE/RBPclasses_20180401.txt\"\n",
    ")\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class#</th>\n",
       "      <th>Class ID</th>\n",
       "      <th>SubmittedDueToFamily</th>\n",
       "      <th>rbp</th>\n",
       "      <th>cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SND1-HepG2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "      <td>SND1</td>\n",
       "      <td>HepG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FXR1-K562</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "      <td>FXR1</td>\n",
       "      <td>K562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SND1-K562</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "      <td>SND1</td>\n",
       "      <td>K562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FXR2-HepG2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "      <td>FXR2</td>\n",
       "      <td>HepG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G3BP1-HepG2</td>\n",
       "      <td>1</td>\n",
       "      <td>CDS</td>\n",
       "      <td>1</td>\n",
       "      <td>G3BP1</td>\n",
       "      <td>HepG2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Class# Class ID  SubmittedDueToFamily    rbp   cell\n",
       "0   SND1-HepG2       1      CDS                     1   SND1  HepG2\n",
       "1    FXR1-K562       1      CDS                     1   FXR1   K562\n",
       "2    SND1-K562       1      CDS                     1   SND1   K562\n",
       "3   FXR2-HepG2       1      CDS                     1   FXR2  HepG2\n",
       "4  G3BP1-HepG2       1      CDS                     1  G3BP1  HepG2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rbp(row):\n",
    "    return row['Unnamed: 0'].split('-')[0]\n",
    "def get_cell(row):\n",
    "    return row['Unnamed: 0'].split('-')[1]\n",
    "classes['rbp'] = classes.apply(get_rbp, axis=1)\n",
    "classes['cell'] = classes.apply(get_cell, axis=1)\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'298'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_rbps_within_same_class(rbp, cell, df=classes):\n",
    "    \"\"\" given an rbp and cell type, return list of other rbps in same binding class. \"\"\"\n",
    "    class_num = df[(df['cell']==cell) & (df['rbp']==rbp)]['Class#'].values[0]\n",
    "    return list(set(df[(df['Class#']==class_num) & (df['cell']==cell)]['Unnamed: 0']))\n",
    "          \n",
    "\n",
    "def get_uid_from_rbp_and_cell(rbp, cell, merged=merged):\n",
    "    \"\"\" given an rbp name and celltype, return uid \"\"\"\n",
    "    return merged[(merged['RBP']==rbp) & (merged['Cell line']==cell)]['uID'].values[0]\n",
    "\n",
    "\n",
    "def get_groupid(rbp, cell, df=classes):\n",
    "    class_num = df[(df['cell']==cell) & (df['rbp']==rbp)]['Class#'].values[0]\n",
    "    return class_num\n",
    "\n",
    "def compare_rbp_against_all_others_in_class(uid, df=classes, merged=merged):\n",
    "    \"\"\" Given an rbp uID, return a list of uIDs in its same group. \"\"\"\n",
    "    all_uids_to_compare = []\n",
    "    r1, r2, i, rbp, cell, jxc_se = get_clip_file_from_uid(uid, df=merged)\n",
    "    rbps_list = return_rbps_within_same_class(rbp, cell, df)\n",
    "    for protein in rbps_list:\n",
    "        rbp_name, cell_type = protein.split('-')\n",
    "        try:\n",
    "            all_uids_to_compare.append(get_uid_from_rbp_and_cell(rbp_name, cell_type))\n",
    "        except IndexError:\n",
    "            # print(rbp_name, cell_type)\n",
    "            pass\n",
    "    if len(all_uids_to_compare) > 0:\n",
    "        return all_uids_to_compare\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "get_groupid('POLR2G','HepG2')\n",
    "compare_rbp_against_all_others_in_class('203')\n",
    "\n",
    "merged.iloc[43]['uID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entries: 203\n",
      "Number of UIDs: 203\n",
      "total_grp: 5223, total comparisons: 19732, total (n >=100): 7866, total redundant: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing 0 tasks as an array-job.\n",
      "Wrote commands to /projects/ps-yeolab3/bay001/maps/bash_scripts/8-22-2018/whole_read_xcompare-SE_XCOMPARE2_png.4.sh.\n"
     ]
    }
   ],
   "source": [
    "ext = 'png'\n",
    "pos_splicing_suffix = '-included-upon-knockdown'\n",
    "neg_splicing_suffix = '-excluded-upon-knockdown'\n",
    "\n",
    "if not os.path.exists(bash_scripts_dir):\n",
    "    ! mkdir $bash_scripts_dir\n",
    "\n",
    "read_type = 'whole_read_xcompare'\n",
    "normalization_level = 4\n",
    "\n",
    "\n",
    "### Force override of maps\n",
    "force = False\n",
    "\n",
    "### DEFINE BACKGROUNDS (THESE ARE STATIC AND DON'T CHANGE) ###\n",
    "k562_background_ce = os.path.join(control_annotation_dir, 'K562_constitutive_exons')\n",
    "k562_background_nse_all = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_all')\n",
    "k562_background_nse_inc = os.path.join(control_annotation_dir, 'K562_natively_included_cassette_exons')\n",
    "k562_background_nse_exc = os.path.join(control_annotation_dir, 'K562_natively_excluded_cassette_exons')\n",
    "k562_background_nse_avg = os.path.join(control_annotation_dir, 'K562_native_cassette_exons_avg')\n",
    "\n",
    "hepg2_background_ce = os.path.join(control_annotation_dir, 'HepG2_constitutive_exons')\n",
    "hepg2_background_nse_all = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_all')\n",
    "hepg2_background_nse_inc = os.path.join(control_annotation_dir, 'HepG2_natively_included_cassette_exons')\n",
    "hepg2_background_nse_exc = os.path.join(control_annotation_dir, 'HepG2_natively_excluded_cassette_exons')\n",
    "hepg2_background_nse_avg = os.path.join(control_annotation_dir, 'HepG2_native_cassette_exons_avg')\n",
    "\n",
    "# manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "# manifest_file = '/projects/ps-yeolab3/bay001/maps/current/se_xcompare_manifest.txt'\n",
    "manifest_file = '/projects/ps-yeolab3/bay001/reference_data/ENCODE/se_xcompare_manifest.txt'\n",
    "o = open(manifest_file, 'w')\n",
    "o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "    \"clip_id\", \"uID\", \"group_id\", \"pos_file_name\", \"neg_file_name\"\n",
    "))\n",
    "print(\"number of entries: {}\".format(len(set(merged['uID']))))\n",
    "\n",
    "TOTAL_GRP_COMPARISONS = 0\n",
    "TOTAL_EXPECT_MEANS = 0  # let's add up the total (expected) number of mean values we're supposed to have.\n",
    "FILTERED_EXPECT_MEANS = 0  # let's add up the filtered (expected) number of mean values we're supposed to have (n >=100).\n",
    "REDUNDANT_MEANS = 0 # i use a placeholder (erics data) for maps that have less than 2 annotations. Let's keep track of these.\n",
    "\n",
    "# no_rnaseq = [] # uIDs for which we don't have rna seq expt ids for\n",
    "cmds = []\n",
    "print(\"Number of UIDs: {}\".format(len(merged['uID'])))\n",
    "for uid in set(sorted(merged['uID'])):\n",
    "    local_cmds = \"module load rbpmaps\"\n",
    "    local_cmds_ct = 0 # count how many local commands we have per uID\n",
    "    r1, r2, i, rbp, cell, _ = get_clip_file_from_uid(uid)\n",
    "    if cell == 'K562':\n",
    "        background2 = k562_background_nse_all\n",
    "        background5 = k562_background_nse_avg\n",
    "    elif cell == 'HepG2':\n",
    "        background2 = hepg2_background_nse_all\n",
    "        background5 = hepg2_background_nse_avg\n",
    "    else:\n",
    "        print(cell)\n",
    "        \n",
    "    other_uids_to_compare = compare_rbp_against_all_others_in_class(uid)\n",
    "    if other_uids_to_compare is not None:\n",
    "        # Just a check to make sure we're making proper comparisons...\n",
    "        other_rbps = []\n",
    "        for x in range(min(5, len(other_uids_to_compare))):  # preview the kinds of RBPs we're comparing against\n",
    "            try:\n",
    "                _, _, _, other_rbp, other_cell, _ = get_clip_file_from_uid(other_uids_to_compare[x])\n",
    "                other_rbps.append(\"{}-{}\".format(other_rbp, other_cell))\n",
    "            except Exception as e:\n",
    "                print(len(other_uids_to_compare))\n",
    "        # print(\"comparing {}-{} to {}..\".format(rbp, cell, other_rbps))\n",
    "\n",
    "        # end check\n",
    "        \n",
    "        # for each RBP to compare:\n",
    "        for other_uid in other_uids_to_compare:\n",
    "            TOTAL_GRP_COMPARISONS += 1\n",
    "            ##### get the positive and negative associated annotations using this prefix #####\n",
    "            _, _, _, _, _, jxc_se = get_clip_file_from_uid(other_uid)\n",
    "            positive, negative = get_annotations_from_jxc_se(\n",
    "                jxc_se\n",
    "            )\n",
    "            \n",
    "            ### both positive and negative annotations to plot ###\n",
    "            if(positive == None and negative == None):  # we don't have any significant events to plot\n",
    "                # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                    os.path.basename(r),\n",
    "                    os.path.basename(jxc_se),\n",
    "                    get_groupid(rbp, cell),\n",
    "                    \"-\",\n",
    "                    \"-\",\n",
    "                ))\n",
    "            elif positive is None:  # we have negative events to plot\n",
    "                \n",
    "                # checks the shape (number of events)\n",
    "                neg_prefix = os.path.basename(negative).split('-')[0]\n",
    "                negdf = pd.read_table(negative)\n",
    "                \n",
    "                # Build the cmd line\n",
    "                for r in [r1, r2]:\n",
    "                    name = os.path.basename(r).replace('.bam','.compare.{}.{}.{}'.format(\n",
    "                        jxc_se.split('.')[0], normalization_level, ext\n",
    "                    ))\n",
    "                    output_filename = os.path.join(\n",
    "                        params[read_type]['output_dir'],\n",
    "                        name\n",
    "                    )\n",
    "                    \n",
    "                    cmd = \"python \" + density_runner\n",
    "                    cmd = cmd + \" --event {}\".format('se')\n",
    "                    cmd = cmd + \" --ipbam {}\".format(r)\n",
    "                    cmd = cmd + \" --inputbam {}\".format(i)\n",
    "                    cmd = cmd + \" --output {}\".format(output_filename)\n",
    "                    cmd = cmd + \" --annotations {} {}\".format(\n",
    "                        negative, background5\n",
    "                    )\n",
    "                    cmd = cmd + \" --annotation_type {} {}\".format(\n",
    "                        'rmats', 'eric'\n",
    "                    )\n",
    "                    cmd = cmd + \" --normalization_level {}\".format(normalization_level)\n",
    "                    if not os.path.exists(output_filename) or force == True:\n",
    "                        # cmds.append(cmd)\n",
    "                        local_cmds = local_cmds + ';{}'.format(cmd)\n",
    "                        local_cmds_ct += 1\n",
    "                    if (negdf.shape[0] < 100):\n",
    "                            # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                            o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                                os.path.basename(r),\n",
    "                                os.path.basename(jxc_se),\n",
    "                                get_groupid(rbp, cell),\n",
    "                                \"-\",\n",
    "                                \"-\",\n",
    "                            ))\n",
    "                    # Else if we have enough events, write build the commandline and write to file.\n",
    "                    else:\n",
    "                        # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                        o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                            os.path.basename(r),\n",
    "                            os.path.basename(jxc_se),\n",
    "                            get_groupid(rbp, cell),\n",
    "                            \"-\",\n",
    "                            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(negative))),\n",
    "                        ))\n",
    "                        FILTERED_EXPECT_MEANS += 1\n",
    "                REDUNDANT_MEANS += 2\n",
    "                TOTAL_EXPECT_MEANS += 2 # negative, negative for each replicate\n",
    "                \n",
    "            elif negative is None:  # we have positive events to plot\n",
    "                # checks the shape (number of events)\n",
    "                pos_prefix = os.path.basename(positive).split('-')[0]\n",
    "                posdf = pd.read_table(positive)\n",
    "                # Build the cmd line\n",
    "                for r in [r1, r2]:\n",
    "                    name = os.path.basename(r).replace('.bam','.compare.{}.{}.{}'.format(\n",
    "                        jxc_se.split('.')[0], normalization_level, ext\n",
    "                    ))\n",
    "                    output_filename = os.path.join(\n",
    "                        params[read_type]['output_dir'],\n",
    "                        name\n",
    "                    )\n",
    "                    cmd = \"python \" + density_runner\n",
    "                    cmd = cmd + \" --event {}\".format('se')\n",
    "                    cmd = cmd + \" --ipbam {}\".format(r)\n",
    "                    cmd = cmd + \" --inputbam {}\".format(i)\n",
    "                    cmd = cmd + \" --output {}\".format(output_filename)\n",
    "                    cmd = cmd + \" --annotations {} {}\".format(\n",
    "                        positive, background5\n",
    "                    )\n",
    "                    cmd = cmd + \" --annotation_type {} {}\".format(\n",
    "                        'rmats', 'eric'\n",
    "                    )\n",
    "                    cmd = cmd + \" --normalization_level {}\".format(normalization_level)\n",
    "                    if not os.path.exists(output_filename) or force == True:\n",
    "                        # cmds.append(cmd)\n",
    "                        local_cmds = local_cmds + ';{}'.format(cmd)\n",
    "                        local_cmds_ct += 1\n",
    "                    if (posdf.shape[0] < 100):\n",
    "                            # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                            o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                                os.path.basename(r),\n",
    "                                os.path.basename(jxc_se),\n",
    "                                get_groupid(rbp, cell),\n",
    "                                \"-\",\n",
    "                                \"-\",\n",
    "                            ))\n",
    "                    # Else if we have enough events, write build the commandline and write to file.\n",
    "                    else:\n",
    "                        # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                        o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                            os.path.basename(r),\n",
    "                            os.path.basename(jxc_se),\n",
    "                            get_groupid(rbp, cell),\n",
    "                            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(positive))),\n",
    "                            \"-\"\n",
    "                        ))\n",
    "                        FILTERED_EXPECT_MEANS += 1\n",
    "                REDUNDANT_MEANS += 2\n",
    "                TOTAL_EXPECT_MEANS += 2 # negative, negative for each replicate\n",
    "            else:\n",
    "                ### uses RBP name to ensure positive and negative annotations are being pulled ###\n",
    "                pos_prefix = os.path.basename(positive).split('-')[0]\n",
    "                neg_prefix = os.path.basename(negative).split('-')[0]\n",
    "                posdf = pd.read_table(positive)\n",
    "                negdf = pd.read_table(negative)\n",
    "\n",
    "\n",
    "                ### Foreach replicate, build teh command used to call the python script.\n",
    "                # Build the cmd line\n",
    "                for r in [r1, r2]:\n",
    "                    name = os.path.basename(r).replace('.bam','.compare.{}.{}.{}'.format(\n",
    "                        jxc_se.split('.')[0], normalization_level, ext\n",
    "                    ))\n",
    "                    output_filename = os.path.join(\n",
    "                        params[read_type]['output_dir'],\n",
    "                        name\n",
    "                    )\n",
    "                    # Build the cmd line\n",
    "                    cmd = \"python \" + density_runner\n",
    "                    cmd = cmd + \" --event {}\".format('se')\n",
    "                    cmd = cmd + \" --ipbam {}\".format(r)\n",
    "                    cmd = cmd + \" --inputbam {}\".format(i)\n",
    "                    cmd = cmd + \" --output {}\".format(output_filename)\n",
    "                    cmd = cmd + \" --annotations {} {}\".format(\n",
    "                        positive, negative\n",
    "                    )\n",
    "                    cmd = cmd + \" --annotation_type {} {}\".format(\n",
    "                        'rmats', 'rmats'\n",
    "                    )\n",
    "                    cmd = cmd + \" --normalization_level {}\".format(normalization_level)\n",
    "                    if not os.path.exists(output_filename) or force == True:\n",
    "                        # cmds.append(cmd)\n",
    "                        local_cmds = local_cmds + ';{}'.format(cmd)\n",
    "                        local_cmds_ct += 1\n",
    "                    ### WRITE MANIFEST ###\n",
    "\n",
    "                    # If there are not enough positive events and not enough negative events: write to file \n",
    "                    if ((posdf.shape[0] < 100) & (negdf.shape[0] < 100)):\n",
    "                        # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                        o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                            os.path.basename(r),\n",
    "                            os.path.basename(jxc_se),\n",
    "                            get_groupid(rbp, cell),\n",
    "                            \"-\",\n",
    "                            \"-\",\n",
    "                        ))\n",
    "                    # Else if we have enough positive events, write build the commandline and write positive to file.\n",
    "                    elif ((posdf.shape[0] >= 100) & (negdf.shape[0] < 100)):\n",
    "                        # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                        o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                            os.path.basename(r),\n",
    "                            os.path.basename(jxc_se),\n",
    "                            get_groupid(rbp, cell),\n",
    "                            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(positive))),\n",
    "                            \"-\"\n",
    "                        ))\n",
    "                        FILTERED_EXPECT_MEANS += 1\n",
    "                    # Else if we have enough negative events but not positive, build commandline with just negative\n",
    "                    elif ((negdf.shape[0] >= 100) & (posdf.shape[0] < 100)):\n",
    "                        # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                        o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                            os.path.basename(r),\n",
    "                            os.path.basename(jxc_se),\n",
    "                            get_groupid(rbp, cell),\n",
    "                            \"-\",\n",
    "                            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(negative))),\n",
    "                        ))\n",
    "                        FILTERED_EXPECT_MEANS += 1\n",
    "                    # Else if we have enough events for both, generate commandline using both\n",
    "                    elif ((negdf.shape[0] >= 100) & (posdf.shape[0] >= 100)):\n",
    "                        # manifest for eric (clip id / rnaseq id / group # / pos / neg)\n",
    "                        o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                            os.path.basename(r),\n",
    "                            os.path.basename(jxc_se),\n",
    "                            get_groupid(rbp, cell),\n",
    "                            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(positive))),\n",
    "                            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(negative))),\n",
    "                        ))\n",
    "                        FILTERED_EXPECT_MEANS += 2\n",
    "                TOTAL_EXPECT_MEANS += 4 # negative, positive for each replicate\n",
    "    if local_cmds != \"module load rbpmaps\":\n",
    "        if local_cmds.startswith(';'):\n",
    "            local_cmds = local_cmds[1:]\n",
    "        print(\"number of cmds written for {}: {}\".format(uid, local_cmds_ct))\n",
    "        cmds.append(local_cmds)\n",
    "o.close()\n",
    "bash_script_sh = '/projects/ps-yeolab3/bay001/maps/bash_scripts/{}/{}-SE_XCOMPARE2_{}.{}.sh'.format(\n",
    "    current_date, \n",
    "    params[read_type]['prefix'], \n",
    "    ext,\n",
    "    normalization_level\n",
    ")\n",
    "\n",
    "Submitter(\n",
    "    cmds, \n",
    "    \"{}-SE_XCOMPARE2_{}\".format(params[read_type]['prefix'], ext), \n",
    "    sh=bash_script_sh,\n",
    "    submit=False,\n",
    "    array=True,\n",
    "    walltime='72:00:00',\n",
    "    queue='home-yeo'\n",
    ")\n",
    "\n",
    "with open(bash_script_sh + \".slow.sh\", 'w') as o:\n",
    "    o.write(\"#!/usr/bin/env bash\\n\")\n",
    "    for cmd in cmds:\n",
    "        o.write(cmd + \"\\n\")\n",
    "\n",
    "### Print any missing/unavailable annotations to check over ###\n",
    "print(\"total_grp: {}, total comparisons: {}, total (n >=100): {}, total redundant: {}\".format(\n",
    "        TOTAL_GRP_COMPARISONS,\n",
    "        TOTAL_EXPECT_MEANS,\n",
    "        FILTERED_EXPECT_MEANS,\n",
    "        REDUNDANT_MEANS\n",
    "        )\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing 0 tasks as an array-job.\n",
      "Wrote commands to /projects/ps-yeolab3/bay001/maps/bash_scripts/8-22-2018/whole_read_xcompare-SE_XCOMPARE_NSE_png.4.sh.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qtools.submitter.Submitter at 0x2b9000b0ee90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmds = []\n",
    "manifest_file = '/projects/ps-yeolab3/bay001/reference_data/ENCODE/se_xcompare_manifest.nSE.txt'\n",
    "o = open(manifest_file, 'w')\n",
    "o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "    \"clip_id\", \"uID\", \"group_id\", \"nSE_all_file_name\", \"nSE_avg_file_name\"\n",
    "))\n",
    "\n",
    "for uid in set(merged['uID']):\n",
    "    # Regardless of how many pos/neg events there are, generate the maps for each RBP with just the (nSE-All and nSE-Avg) annotations.\n",
    "    r1, r2, i, rbp, cell, _ = get_clip_file_from_uid(uid)\n",
    "    if cell == 'K562':\n",
    "        background2 = k562_background_nse_all\n",
    "        background5 = k562_background_nse_avg\n",
    "    elif cell == 'HepG2':\n",
    "        background2 = hepg2_background_nse_all\n",
    "        background5 = hepg2_background_nse_avg\n",
    "    else:\n",
    "        print(cell)\n",
    "\n",
    "    for r in [r1, r2]:\n",
    "        name = os.path.basename(r).replace('.bam','.compare.nSE.{}.{}'.format(\n",
    "            normalization_level, ext\n",
    "        ))\n",
    "        output_filename = os.path.join(\n",
    "            params[read_type]['output_dir'],\n",
    "            name\n",
    "        )\n",
    "        allmeans = os.path.join(\n",
    "            params[read_type]['output_dir'],\n",
    "            \"{}*{}*native_cassette_exons_all.means.txt\".format(uid, uid)\n",
    "        )\n",
    "        avgmeans = os.path.join(\n",
    "            params[read_type]['output_dir'],\n",
    "            \"{}*{}*native_cassette_exons_avg.means.txt\".format(uid, uid)\n",
    "        )\n",
    "        # Build the cmd line\n",
    "\n",
    "        cmd = \"python \" + density_runner\n",
    "        cmd = cmd + \" --event {}\".format('se')\n",
    "        cmd = cmd + \" --ipbam {}\".format(r)\n",
    "        cmd = cmd + \" --inputbam {}\".format(i)\n",
    "        cmd = cmd + \" --output {}\".format(output_filename)\n",
    "        cmd = cmd + \" --annotations {} {}\".format( \n",
    "            background2, background5,\n",
    "        )\n",
    "        cmd = cmd + \" --annotation_type {} {}\".format( \n",
    "            'eric', 'eric',\n",
    "        )\n",
    "        cmd = cmd + \" --normalization_level {}\".format(normalization_level)\n",
    "        o.write(\"{}\\t{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "            os.path.basename(r),\n",
    "            '-',\n",
    "            get_groupid(rbp, cell),\n",
    "            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(background2))),\n",
    "            output_filename.replace('.{}'.format(ext), '.{}.means.txt'.format(os.path.basename(background5))),\n",
    "        ))\n",
    "        if not os.path.exists(output_filename) or force == True:\n",
    "            cmds.append(cmd)\n",
    "o.close()\n",
    "bash_script_sh = '/projects/ps-yeolab3/bay001/maps/bash_scripts/{}/{}-SE_XCOMPARE_NSE_{}.{}.sh'.format(\n",
    "    current_date, \n",
    "    params[read_type]['prefix'], \n",
    "    ext,\n",
    "    normalization_level\n",
    ")\n",
    "\n",
    "Submitter(\n",
    "    cmds, \n",
    "    \"{}-SE_XCOMPARE_NSE_{}\".format(params[read_type]['prefix'], ext), \n",
    "    sh=bash_script_sh,\n",
    "    submit=False,\n",
    "    array=True,\n",
    "    walltime='6:00:00',\n",
    "    queue='home-yeo'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's check to make sure we've made all se splice maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386 corresponds to 193 RBPs with both eCLIP and RMATS significant events\n"
     ]
    }
   ],
   "source": [
    "# this is the total number of maps we've made. This includes both replicates, and only contains maps for expts which have at least 1 significant positive and negative event\n",
    "num_maps = len(glob.glob(os.path.join(params['whole_read']['output_dir'], \"*.svg\")))\n",
    "\n",
    "print(\"{} corresponds to {} RBPs with both eCLIP and RMATS significant events\".format(num_maps, num_maps/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of downloaded files (should be 473): 473\n"
     ]
    }
   ],
   "source": [
    "# Ensure that we have the correct number of rmats files by re-filtering them independently:\n",
    "orig_jxc_dir = '/projects/ps-yeolab3/encode/rnaseq/alt_splicing/graveley_rmats_current' # where we downloaded data from xintao\n",
    "out_dir = '/home/bay001/scratch/encode/rmats_subset_test' # we don't need to keep any of these, just calculate the number\n",
    "jxc_files = glob.glob(os.path.join(orig_jxc_dir, '*.SE.MATS.JunctionCountOnly.txt')) # all jxc SE files\n",
    "print(\"Total number of downloaded files (should be 473): {}\".format(len(jxc_files)))\n",
    "\n",
    "def subset_jxc_only(in_file, out_file):\n",
    "    \"\"\"\n",
    "    Calls my 'nonredundant' script to return nonoverlapping splice events.\n",
    "    \"\"\"\n",
    "    scripts_dir = '/home/bay001/projects/codebase/bfx/pyscripts/rnaseq/'\n",
    "    cmd = 'python {} '.format(\n",
    "        os.path.join(scripts_dir, 'subset_rmats_junctioncountonly.py')\n",
    "    )\n",
    "    cmd += '-i {} '.format(in_file)\n",
    "    cmd += '-o {} '.format(out_file)\n",
    "    cmd += '-e {} '.format('se')\n",
    "    ! $cmd\n",
    "    \n",
    "def filter_jxc_file(fn, fdr=0.1, pvalue=0.05, sep=0.05, out_dir=out_dir):\n",
    "    \"\"\" filters a JunctionCountsOnly file and saves significant up/down/all SE splice events. \"\"\"\n",
    "    dfp_size = 0\n",
    "    dfn_size = 0\n",
    "    \n",
    "    df = pd.read_table(fn)\n",
    "    dfs = df[(df['PValue'] < pvalue) & (df['FDR'] < fdr)]\n",
    "    dfs_output = os.path.join(out_dir, os.path.basename(fn) + '.significant.txt')\n",
    "    if dfs.shape[0] > 0:\n",
    "        dfs.to_csv(dfs_output, sep='\\t', index=False)\n",
    "    \n",
    "    dfp = df[(df['PValue'] < pvalue) & (df['IncLevelDifference'] > sep) & (df['FDR'] < fdr)]\n",
    "    dfp_output = os.path.join(out_dir, os.path.basename(fn) + '.positive.txt')\n",
    "    dfp_output_nr = os.path.join(out_dir, os.path.basename(fn) + '.positive.nr.txt')\n",
    "    if dfp.shape[0] > 0:\n",
    "        dfp.to_csv(dfp_output, sep='\\t', index=False)\n",
    "        subset_jxc_only(dfp_output, dfp_output_nr)\n",
    "        dfp_size = pd.read_table(dfp_output_nr).shape[0]\n",
    "        \n",
    "    dfn = df[(df['PValue'] < pvalue) & (df['IncLevelDifference'] < -(sep)) & (df['FDR'] < fdr)]\n",
    "    dfn_output = os.path.join(out_dir, os.path.basename(fn) + '.negative.txt')\n",
    "    dfn_output_nr = os.path.join(out_dir, os.path.basename(fn) + '.negative.nr.txt')\n",
    "    if dfn.shape[0] > 0:\n",
    "        dfn.to_csv(dfn_output, sep='\\t', index=False)\n",
    "        subset_jxc_only(dfn_output, dfn_output_nr)\n",
    "        dfn_size = pd.read_table(dfn_output_nr).shape[0]\n",
    "    \n",
    "    return dfs.shape[0], dfp.shape[0], dfn.shape[0], dfp_size, dfn_size\n",
    "    \n",
    "def get_filtered_jxc_num(jxc_files):\n",
    "    \"\"\"\n",
    "    Iterates over filter_jxc_file() and returns a dictionary of the number of \n",
    "    significantly up/down/all SE events.\n",
    "    \"\"\"\n",
    "    jxc_dict = defaultdict(dict)\n",
    "    progress = tnrange(len(jxc_files))\n",
    "    for jxc_file in jxc_files:\n",
    "        significant, positive, negative, positive_nr, negative_nr = filter_jxc_file(jxc_file)\n",
    "        jxc_dict[os.path.basename(jxc_file)] = {'sig':significant,'pos':positive,'neg':negative, 'pos_nr':positive_nr, 'neg_nr':negative_nr}\n",
    "        progress.update(1)\n",
    "    return jxc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc08e01fc16e46039fd561c8336dbd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=473), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jxc_dict = get_filtered_jxc_num(jxc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough negative events: GRWD1-K562 GRWD1-BGKLV21-K562.set21.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: CSTF2T-K562 CSTF2T-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: AKAP1-K562 AKAP1-LV08-K562.set10.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: EXOSC5-HepG2 EXOSC5-BGHcLV07-HepG2.set39_H.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: LSM11-K562 LSM11-BGKLV21-K562.set21.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: FASTKD2-K562 FASTKD2-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: SLTM-K562 SLTM-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: DDX52-K562 DDX52-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: FAM120A-K562 FAM120A-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt\n",
      "not enough positive events: DDX51-K562 DDX51-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt\n",
      "we have 193 valid filtered+nonredundant JXC files.\n"
     ]
    }
   ],
   "source": [
    "# make a copy of the merged manifest so we can delete stuff without worrying about modifying original dataframe\n",
    "merged2 = merged.copy(deep=True)  \n",
    "# convert rbp+cell line into a single string that we can search/use as a unique key\n",
    "merged2['code'] = merged2.apply(lambda x: '{}-{}'.format(x['RBP'], x['Cellline']), axis=1) \n",
    "# check manually if these numbers match what is being printed in the figure:\n",
    "for fn, num_events in jxc_dict.iteritems(): \n",
    "    # first check to see if jxc file is needed at all (is in our \"final\" matrix)\n",
    "    if fn in set(merged['SE_jxc_file']):\n",
    "        cell = fn.split('-')[2].split('.')[0]\n",
    "        # if there are 0 sig events for this file, exclude this rbp+cell from this study (remove the row)\n",
    "        if jxc_dict[fn]['pos_nr'] == 0:\n",
    "            rbp = fn.split('-')[0]\n",
    "            \n",
    "            code = '{}-{}'.format(rbp, cell)\n",
    "            print('not enough positive events: {} {}'.format(code, fn))\n",
    "            merged2 = merged2[merged2['code']!=code]\n",
    "        elif jxc_dict[fn]['neg_nr'] == 0:\n",
    "            rbp = fn.split('-')[0]\n",
    "            code = '{}-{}'.format(rbp, cell)\n",
    "            print('not enough negative events: {} {}'.format(code, fn))\n",
    "            merged2 = merged2[merged2['code']!=code]\n",
    "\n",
    "print(\"we have {} valid filtered+nonredundant JXC files.\".format(merged2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The numbers match up so far...\n",
    "- 193 valid jxc files with eCLIP is 10 less than 203 total jxc + eCLIP.\n",
    "- double check that the 10 samples truly don't have enough significant events to be mapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of invalid/insufficient samples: 10\n",
      "fn: CSTF2T-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt sig: 0 pos: 0 pos_nr: 0 neg: 0 neg_nr: 0\n",
      "fn: EXOSC5-BGHcLV07-HepG2.set39_H.SE.MATS.JunctionCountOnly.txt sig: 0 pos: 0 pos_nr: 0 neg: 0 neg_nr: 0\n",
      "fn: DDX51-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt sig: 1 pos: 0 pos_nr: 0 neg: 1 neg_nr: 1\n",
      "fn: DDX52-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt sig: 0 pos: 0 pos_nr: 0 neg: 0 neg_nr: 0\n",
      "fn: AKAP1-LV08-K562.set10.SE.MATS.JunctionCountOnly.txt sig: 9 pos: 0 pos_nr: 0 neg: 7 neg_nr: 7\n",
      "fn: FAM120A-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt sig: 1 pos: 0 pos_nr: 0 neg: 1 neg_nr: 1\n",
      "fn: GRWD1-BGKLV21-K562.set21.SE.MATS.JunctionCountOnly.txt sig: 2 pos: 2 pos_nr: 2 neg: 0 neg_nr: 0\n",
      "fn: LSM11-BGKLV21-K562.set21.SE.MATS.JunctionCountOnly.txt sig: 2 pos: 0 pos_nr: 0 neg: 0 neg_nr: 0\n",
      "fn: FASTKD2-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt sig: 0 pos: 0 pos_nr: 0 neg: 0 neg_nr: 0\n",
      "fn: SLTM-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt sig: 5 pos: 0 pos_nr: 0 neg: 4 neg_nr: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"number of invalid/insufficient samples: {}\".format(\n",
    "    len(set(merged['SE_jxc_file']).difference(set(merged2['SE_jxc_file']))))\n",
    ")\n",
    "list_of_insignificant_jxc_files = list(set(merged['SE_jxc_file']).difference(set(merged2['SE_jxc_file'])))\n",
    "for fn in list_of_insignificant_jxc_files:\n",
    "    fn = os.path.join(orig_jxc_dir, fn)\n",
    "    significant, positive, negative, positive_nr, negative_nr = filter_jxc_file(fn)\n",
    "    print(\"fn: {} sig: {} pos: {} pos_nr: {} neg: {} neg_nr: {}\".format(os.path.basename(fn), significant, positive, positive_nr, negative, negative_nr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CSTF2T-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt',\n",
       " 'EXOSC5-BGHcLV07-HepG2.set39_H.SE.MATS.JunctionCountOnly.txt',\n",
       " 'DDX51-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt',\n",
       " 'DDX52-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt',\n",
       " 'AKAP1-LV08-K562.set10.SE.MATS.JunctionCountOnly.txt',\n",
       " 'FAM120A-BGKLV19-K562.set19.SE.MATS.JunctionCountOnly.txt',\n",
       " 'GRWD1-BGKLV21-K562.set21.SE.MATS.JunctionCountOnly.txt',\n",
       " 'LSM11-BGKLV21-K562.set21.SE.MATS.JunctionCountOnly.txt',\n",
       " 'FASTKD2-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt',\n",
       " 'SLTM-BGKLV13-K562.set13.SE.MATS.JunctionCountOnly.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_insignificant_jxc_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKAP1 K562 has 9 significant events but only 7 significant negative events\n",
    "- make sure the IncLevelDifference is responsible for this difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKAP1_K562 = pd.read_table(os.path.join(orig_jxc_dir, 'AKAP1-LV08-K562.set10.SE.MATS.JunctionCountOnly.txt'))\n",
    "print(\n",
    "    \"Number passing pvalue/fdr: {}\".format(\n",
    "        AKAP1_K562[(AKAP1_K562['FDR'] < 0.1) & (AKAP1_K562['PValue'] < 0.05)].shape[0]\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Number of sig. pos: {}\".format(\n",
    "        AKAP1_K562[(AKAP1_K562['FDR'] < 0.1) & (AKAP1_K562['PValue'] < 0.05) & (AKAP1_K562['IncLevelDifference'] > 0.05)].shape[0]\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Number of sig. neg: {}\".format(\n",
    "        AKAP1_K562[(AKAP1_K562['FDR'] < 0.1) & (AKAP1_K562['PValue'] < 0.05) & (AKAP1_K562['IncLevelDifference'] < -0.05)].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check splice map manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\n",
    "    '/projects/ps-yeolab3/bay001/maps/current/se_xcompare_manifest.txt'\n",
    ")\n",
    "print(df.shape)\n",
    "print(len(set(df['rnaseq_id'])))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\n",
    "    \"/projects/ps-yeolab3/bay001/maps/current_annotations/se/HNRNPA1-BGKLV21-K562.set21.SE.MATS.JunctionCountOnly.txt\"\n",
    ")\n",
    "print(df[(df['IncLevelDifference']>=0.05) & (df['PValue']<=0.05) & (df['FDR']<=0.1)].shape)\n",
    "print(df[(df['IncLevelDifference']<=-0.05) & (df['PValue']<=0.05) & (df['FDR']<=0.1)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list of nSE control mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hepg2_files = glob.glob(\"/projects/ps-yeolab3/bay001/maps/current/se_xcompare/*.1.HepG2_native_cassette_exons_all.means.txt\")\n",
    "all_k562_files = glob.glob(\"/projects/ps-yeolab3/bay001/maps/current/se_xcompare/*.1.K562_native_cassette_exons_all.means.txt\")\n",
    "print(len(all_hepg2_files), len(all_k562_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kept_hepg2_files = []\n",
    "all_kept_k562_files = []\n",
    "\n",
    "for fn in all_hepg2_files:\n",
    "    if '.compare' not in fn:\n",
    "        all_kept_hepg2_files.append(fn)\n",
    "\n",
    "for fn in all_k562_files:\n",
    "    if '.compare' not in fn:\n",
    "        all_kept_k562_files.append(fn)\n",
    "        \n",
    "print(len(all_kept_hepg2_files), len(all_kept_k562_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kept_hepg2_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare values in scratch vs permanent storage (yeolab3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_excluded = glob.glob('/projects/ps-yeolab3/bay001/maps/current/se_idr_peak/*excluded-upon-knockdown.hist.txt')\n",
    "print(len(all_excluded))\n",
    "for excluded in all_excluded:\n",
    "    permanent = glob.glob(os.path.join('/home/bay001/scratch/maps/se/idr/', os.path.basename(excluded)))\n",
    "    if len(permanent) != 1:\n",
    "        print(excluded)\n",
    "    else:\n",
    "        permanent = permanent[0]\n",
    "        ! diff $permanent $excluded | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_included = glob.glob('/projects/ps-yeolab3/bay001/maps/current/se_idr_peak/*included-upon-knockdown.hist.txt')\n",
    "print(len(all_excluded))\n",
    "for included in all_included:\n",
    "    permanent = glob.glob(os.path.join('/home/bay001/scratch/maps/se/idr/', os.path.basename(included)))\n",
    "    if len(permanent) != 1:\n",
    "        print(included)\n",
    "    else:\n",
    "        permanent = permanent[0]\n",
    "        ! diff $permanent $included | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_excluded = glob.glob('/projects/ps-yeolab3/bay001/maps/current/se_peak/*excluded-upon-knockdown.hist.txt')\n",
    "print(len(all_excluded))\n",
    "for excluded in all_excluded:\n",
    "    permanent = glob.glob(os.path.join('/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/peak_bb/', os.path.basename(excluded)))\n",
    "    if len(permanent) != 1:\n",
    "        print(excluded)\n",
    "    else:\n",
    "        permanent = permanent[0]\n",
    "        ! diff $permanent $excluded | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_excluded = glob.glob('/projects/ps-yeolab3/bay001/maps/current/se_peak/*excluded-upon-knockdown.hist.txt')\n",
    "print(len(all_excluded))\n",
    "for excluded in all_excluded:\n",
    "    permanent = glob.glob(os.path.join('/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/peak_bb/', os.path.basename(excluded)))\n",
    "    if len(permanent) != 1:\n",
    "        print(excluded)\n",
    "    else:\n",
    "        permanent = permanent[0]\n",
    "        ! diff $permanent $excluded | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>uID</th>\n",
       "      <th>group_id</th>\n",
       "      <th>pos_file_name</th>\n",
       "      <th>neg_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216_01_SRSF9.merged.r2.bam</td>\n",
       "      <td>U2AF1-BGHLV30-HepG2.set30.SE.MATS.JunctionCountOnly.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-included-upon-knockdown.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-excluded-upon-knockdown.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216_02_SRSF9.merged.r2.bam</td>\n",
       "      <td>U2AF1-BGHLV30-HepG2.set30.SE.MATS.JunctionCountOnly.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-included-upon-knockdown.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-excluded-upon-knockdown.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216_01_SRSF9.merged.r2.bam</td>\n",
       "      <td>SF3A3-BGHLV33-HepG2.set33.SE.MATS.JunctionCountOnly.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-included-upon-knockdown.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-excluded-upon-knockdown.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216_02_SRSF9.merged.r2.bam</td>\n",
       "      <td>SF3A3-BGHLV33-HepG2.set33.SE.MATS.JunctionCountOnly.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-included-upon-knockdown.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-excluded-upon-knockdown.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216_01_SRSF9.merged.r2.bam</td>\n",
       "      <td>U2AF2-BGHLV26-HepG2.set26.SE.MATS.JunctionCountOnly.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF2-BGHLV26-HepG2.4.U2AF2-BGHLV26-HepG2.set26-included-upon-knockdown.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF2-BGHLV26-HepG2.4.U2AF2-BGHLV26-HepG2.set26-excluded-upon-knockdown.means.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      clip_id  \\\n",
       "0  216_01_SRSF9.merged.r2.bam   \n",
       "1  216_02_SRSF9.merged.r2.bam   \n",
       "2  216_01_SRSF9.merged.r2.bam   \n",
       "3  216_02_SRSF9.merged.r2.bam   \n",
       "4  216_01_SRSF9.merged.r2.bam   \n",
       "\n",
       "                                                       uID  group_id  \\\n",
       "0  U2AF1-BGHLV30-HepG2.set30.SE.MATS.JunctionCountOnly.txt         2   \n",
       "1  U2AF1-BGHLV30-HepG2.set30.SE.MATS.JunctionCountOnly.txt         2   \n",
       "2  SF3A3-BGHLV33-HepG2.set33.SE.MATS.JunctionCountOnly.txt         2   \n",
       "3  SF3A3-BGHLV33-HepG2.set33.SE.MATS.JunctionCountOnly.txt         2   \n",
       "4  U2AF2-BGHLV26-HepG2.set26.SE.MATS.JunctionCountOnly.txt         2   \n",
       "\n",
       "                                                                                                                                                                              pos_file_name  \\\n",
       "0  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-included-upon-knockdown.means.txt   \n",
       "1  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-included-upon-knockdown.means.txt   \n",
       "2  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-included-upon-knockdown.means.txt   \n",
       "3  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-included-upon-knockdown.means.txt   \n",
       "4  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF2-BGHLV26-HepG2.4.U2AF2-BGHLV26-HepG2.set26-included-upon-knockdown.means.txt   \n",
       "\n",
       "                                                                                                                                                                              neg_file_name  \n",
       "0  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-excluded-upon-knockdown.means.txt  \n",
       "1  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.U2AF1-BGHLV30-HepG2.4.U2AF1-BGHLV30-HepG2.set30-excluded-upon-knockdown.means.txt  \n",
       "2  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-excluded-upon-knockdown.means.txt  \n",
       "3  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.SF3A3-BGHLV33-HepG2.4.SF3A3-BGHLV33-HepG2.set33-excluded-upon-knockdown.means.txt  \n",
       "4  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.U2AF2-BGHLV26-HepG2.4.U2AF2-BGHLV26-HepG2.set26-excluded-upon-knockdown.means.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('/projects/ps-yeolab3/bay001/reference_data/ENCODE/se_xcompare_manifest.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa00ae963b604fefb22b45cd9d187220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10228), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-896524c1b258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'wc -l $pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;36m1400\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "progress = tnrange(len(df['pos_file_name']))\n",
    "for pos in df['pos_file_name']:\n",
    "    if pos != '-':\n",
    "        x = ! wc -l $pos\n",
    "        assert 1400 == int(list(x)[0].split(' ')[0])\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ceb789d279d453ba590d81982885776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10228), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "progress = tnrange(len(df['neg_file_name']))\n",
    "for neg in df['neg_file_name']:\n",
    "    if neg != '-':\n",
    "        x = ! wc -l $neg\n",
    "        try:\n",
    "            assert 1400 == int(list(x)[0].split(' ')[0])\n",
    "        except Exception as e:\n",
    "            print(x)\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_id</th>\n",
       "      <th>uID</th>\n",
       "      <th>group_id</th>\n",
       "      <th>nSE_all_file_name</th>\n",
       "      <th>nSE_avg_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216_01_SRSF9.merged.r2.bam</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216_02_SRSF9.merged.r2.bam</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215_01_TIA1.merged.r2.bam</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_01_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_01_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215_02_TIA1.merged.r2.bam</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_02_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_02_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211_01_IGF2BP3.merged.r2.bam</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/211_01_IGF2BP3.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt</td>\n",
       "      <td>/home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/211_01_IGF2BP3.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        clip_id uID  group_id  \\\n",
       "0    216_01_SRSF9.merged.r2.bam   -         2   \n",
       "1    216_02_SRSF9.merged.r2.bam   -         2   \n",
       "2     215_01_TIA1.merged.r2.bam   -         6   \n",
       "3     215_02_TIA1.merged.r2.bam   -         6   \n",
       "4  211_01_IGF2BP3.merged.r2.bam   -         6   \n",
       "\n",
       "                                                                                                                                          nSE_all_file_name  \\\n",
       "0    /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt   \n",
       "1    /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt   \n",
       "2     /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_01_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt   \n",
       "3     /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_02_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt   \n",
       "4  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/211_01_IGF2BP3.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_all.means.txt   \n",
       "\n",
       "                                                                                                                                          nSE_avg_file_name  \n",
       "0    /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_01_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt  \n",
       "1    /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/216_02_SRSF9.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt  \n",
       "2     /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_01_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt  \n",
       "3     /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/215_02_TIA1.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt  \n",
       "4  /home/bay001/projects/brian_rbpmaps_20180202/temporary_data/se_xcompare/211_01_IGF2BP3.merged.r2.compare.nSE.4.HepG2_native_cassette_exons_avg.means.txt  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('/projects/ps-yeolab3/bay001/reference_data/ENCODE/se_xcompare_manifest.nSE.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416357bdc7894cb0abab14ef1dde84a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=406), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "progress = tnrange(len(df['nSE_all_file_name']))\n",
    "for a in df['nSE_all_file_name']:\n",
    "    if pos != '-':\n",
    "        x = ! wc -l $a\n",
    "        assert 1400 == int(list(x)[0].split(' ')[0])\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54813c0cdcc44780abfb9174df683ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=406), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress = tnrange(len(df['nSE_avg_file_name']))\n",
    "for a in df['nSE_avg_file_name']:\n",
    "    if pos != '-':\n",
    "        x = ! wc -l $a\n",
    "        assert 1400 == int(list(x)[0].split(' ')[0])\n",
    "    progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brian",
   "language": "python",
   "name": "brian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {
    "569a4a5b3e314a91ab2b92dcfc9868e4": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
