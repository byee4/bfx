{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pysam\n",
    "import pybedtools\n",
    "import glob\n",
    "from collections import defaultdict, OrderedDict\n",
    "from subprocess import Popen, PIPE, check_call\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_output = '/projects/ps-yeolab3/bay001/for_eric/scratch/B_samples/non_encode_batch19/results/'\n",
    "curr_output = '/projects/ps-yeolab4/bay001/tmp/non_encode_batch19_2/results/'\n",
    "\n",
    "prev_version = '0.4.0'\n",
    "curr_version = '0.4.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_extensions_from_version(version):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the extensions used for each version.\n",
    "    \"\"\"\n",
    "    extensions = defaultdict(str)\n",
    "    if version == '0.2.2':\n",
    "        extensions['trimmed_fastqs'] = '*.r1TrTr.fq.gz'\n",
    "        extensions['repeat_alignments'] = '*.r1TrTr.sorted.STARAligned.out.bam'\n",
    "        extensions['genome_alignments'] = '*.r1TrTr.sorted.STARUnmapped.out.sorted.STARAligned.outSo.bam'\n",
    "        extensions['clipper_peaks'] = '*.r1TrTr.sorted.STARUnmapped.out.sorted.STARAligned.outSo.rmDupSo.peakClusters.bed'\n",
    "        extensions['inputnorm_peaks'] = '*.r1TrTr.sorted.STARUnmapped.out.sorted.STARAligned.outSo.rmDupSo.peakClusters.normed.compressed.bed'\n",
    "    elif version == '0.4.0':\n",
    "        extensions['trimmed_fastqs'] = '*.r1.fqTrTr.sorted.fq.gz'\n",
    "        extensions['repeat_alignments'] = '*.r1.fq.repeat-mapped.bam'\n",
    "        extensions['genome_alignments'] = '*.r1.fq.genome-mappedSoSo.bam'\n",
    "        extensions['clipper_peaks'] = '*.r1.fq.genome-mappedSoSo.rmDupSo.peakClusters.bed'\n",
    "        extensions['inputnorm_peaks'] = '*.r1.fq.genome-mappedSoSo.rmDupSo.peakClusters.normed.compressed.bed'\n",
    "    else:\n",
    "        print(\"Version not supported yet\")\n",
    "        return 1\n",
    "    return extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ext_dict = get_file_extensions_from_version('0.4.0')\n",
    "prev_trimmed_fastqs = sorted(glob.glob(os.path.join(prev_output, file_ext_dict['trimmed_fastqs'])))\n",
    "len(prev_trimmed_fastqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ext_dict = get_file_extensions_from_version('0.4.0')\n",
    "curr_trimmed_fastqs = sorted(glob.glob(os.path.join(curr_output, file_ext_dict['trimmed_fastqs'])))\n",
    "len(curr_trimmed_fastqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_reads_from_fastq(fastq):\n",
    "    \"\"\"\n",
    "    Returns the number of \n",
    "    \"\"\"\n",
    "    cmd = \"zcat {} | wc -l\".format(fastq)\n",
    "    x = Popen(cmd, stdout=PIPE, shell=True)\n",
    "    num_lines = int(x.communicate()[0].strip())\n",
    "    try:\n",
    "        assert num_lines % 4 == 0 # otherwise this might be a truncated fastq.\n",
    "        return int(num_lines/4)\n",
    "    except AssertionError:\n",
    "        print(\"Number of lines not divisible by 4!\")\n",
    "        return -1\n",
    "    \n",
    "def compare_trimmed_fastqs(fastqs):\n",
    "    \"\"\"\n",
    "    returns the ratio of min/max reads for two fastq files. \n",
    "    also returns a dictionary of the actual reads for each fastq.\n",
    "    \"\"\"\n",
    "    num_reads_dict = OrderedDict()\n",
    "    num_reads_arr = []\n",
    "    for fastq in fastqs:\n",
    "        num_read = get_num_reads_from_fastq(fastq)\n",
    "        num_reads_dict[os.path.basename(fastq)] = num_read\n",
    "        num_reads_arr.append(num_read)\n",
    "    \n",
    "    try:\n",
    "        assert num_reads_arr[0] == num_reads_arr[1]\n",
    "        similarity = 1\n",
    "    except AssertionError:\n",
    "        similarity = min(num_reads_arr)/float(max(num_reads_arr))\n",
    "        \n",
    "    return similarity, num_reads_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e9acb8eea153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_trimmed_fastqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_trimmed_fastqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_trimmed_fastqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "compare_trimmed_fastqs([curr_trimmed_fastqs[1], curr_trimmed_fastqs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ext_dict = get_file_extensions_from_version('0.4.0')\n",
    "prev_genome_bams = sorted(glob.glob(os.path.join(prev_output, file_ext_dict['repeat_alignments'])))\n",
    "prev_genome_bams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ext_dict = get_file_extensions_from_version('0.4.0')\n",
    "curr_genome_bams = sorted(glob.glob(os.path.join(curr_output, file_ext_dict['repeat_alignments'])))\n",
    "curr_genome_bams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DIR = \"/home/bay001/scratch/.tmp/\"\n",
    "def get_mapped_num_from_bam_file(bam):\n",
    "    \"\"\" \n",
    "    From a bam file, return the number of mapped reads. \n",
    "    If the bam file is unsorted or unindexed, this function will sort/index \n",
    "    \"\"\"\n",
    "    if not os.path.exists(bam + '.bai'):\n",
    "        try:\n",
    "            check_call([\"samtools index {}\".format(bam)], shell=True)\n",
    "        except Exception as e:\n",
    "            sorted_bam = os.path.join(TMP_DIR, os.path.basename(bam) + \".sorted.bam\")\n",
    "            check_call([\"samtools sort -o {} {}\".format(sorted_bam, bam)], shell=True)\n",
    "            check_call([\"samtools index {}\".format(sorted_bam)], shell=True)\n",
    "            bam = sorted_bam\n",
    "    samfile = pysam.AlignmentFile(bam, \"rb\")\n",
    "    print(samfile.mapped)\n",
    "    return samfile.mapped\n",
    "\n",
    "def compare_bam_files(bams):\n",
    "    \"\"\"\n",
    "    Returns the ratio of min/max read numbers from two bam files\n",
    "    Also returns a dictionary containing the mapped read numbers for each bam file.\n",
    "    \"\"\"\n",
    "    num_mapped_reads_dict = OrderedDict()\n",
    "    num_mapped_reads_arr = []\n",
    "    for bam in bams:\n",
    "        num_mapped_reads = get_mapped_num_from_bam_file(bam)\n",
    "        num_mapped_reads_dict[os.path.basename(bam)] = num_mapped_reads\n",
    "        num_mapped_reads_arr.append(num_mapped_reads)\n",
    "    \n",
    "    try:\n",
    "        assert num_mapped_reads_arr[0] == num_mapped_reads_arr[1]\n",
    "        similarity = 1\n",
    "    except AssertionError:\n",
    "        similarity = min(num_mapped_reads_arr)/float(max(num_mapped_reads_arr))\n",
    "        \n",
    "    return similarity, num_mapped_reads_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_bam_files([prev_genome_bams[0], curr_genome_bams[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bed_files(beds):\n",
    "    num_intervals = []\n",
    "    bedtools = []\n",
    "    num_intervals_dict = defaultdict(int)\n",
    "    for bed in sorted(beds):\n",
    "        bedtool = pybedtools.BedTool(bed)\n",
    "        bedtool = bedtool.merge(s=True, c='4,5,6', o='distinct,distinct,distinct')\n",
    "        num_intervals.append(bedtool.count()) # after merge\n",
    "        num_intervals_dict[os.path.basename(bed)] = bedtool.count()\n",
    "        bedtools.append(bedtool)\n",
    "    assert len(bedtools) == 2\n",
    "    num_intersecting = bedtools[0].intersect(\n",
    "        bedtools[1], f=0.50, r=True, s=True\n",
    "    ).count()\n",
    "    similarity = [\n",
    "        (num_intersecting / float(num_intervals[0])),\n",
    "        (num_intersecting / float(num_intervals[1]))\n",
    "    ]\n",
    "    return similarity, num_intervals_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_file_ext_dict = get_file_extensions_from_version(prev_version)\n",
    "prev_beds = sorted(glob.glob(os.path.join(prev_output, prev_file_ext_dict['clipper_peaks'])))\n",
    "\n",
    "curr_file_ext_dict = get_file_extensions_from_version(curr_version)\n",
    "curr_beds = sorted(glob.glob(os.path.join(curr_output, curr_file_ext_dict['clipper_peaks'])))\n",
    "\n",
    "curr_beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_beds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_bed_files([prev_beds[0], curr_beds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix(fn):\n",
    "    \"\"\"\n",
    "    Assumes that the first two elements of a file correspond to the dataset and sample, which \n",
    "    in combination will be unique.\n",
    "    \"\"\"\n",
    "    parts = os.path.basename(fn).split('.')\n",
    "    return '.'.join([parts[0], parts[1]]) # returns the dataset (batch) name and the sample name.\n",
    "\n",
    "def compare_outputs(prev_output, prev_version, curr_output, curr_version):\n",
    "    \"\"\"\n",
    "    Returns the prefix of files from previous and current output directories. \n",
    "    This shouldn't change unless the filename structure changes.\n",
    "    \"\"\"\n",
    "    prev_file_ext_dict = get_file_extensions_from_version(prev_version)\n",
    "    curr_file_ext_dict = get_file_extensions_from_version(curr_version)\n",
    "    \n",
    "    prev_trimmed_fastqs = sorted(glob.glob(os.path.join(prev_output, prev_file_ext_dict['trimmed_fastqs'])))\n",
    "    curr_trimmed_fastqs = sorted(glob.glob(os.path.join(curr_output, curr_file_ext_dict['trimmed_fastqs'])))\n",
    "    \n",
    "    prev_repeat_alignments = sorted(glob.glob(os.path.join(prev_output, prev_file_ext_dict['repeat_alignments'])))\n",
    "    curr_repeat_alignments = sorted(glob.glob(os.path.join(curr_output, curr_file_ext_dict['repeat_alignments'])))\n",
    "    \n",
    "    prev_genome_alignments = sorted(glob.glob(os.path.join(prev_output, prev_file_ext_dict['genome_alignments'])))\n",
    "    curr_genome_alignments = sorted(glob.glob(os.path.join(curr_output, curr_file_ext_dict['genome_alignments'])))\n",
    "    \n",
    "    prev_clipper_peaks = sorted(glob.glob(os.path.join(prev_output, prev_file_ext_dict['clipper_peaks'])))\n",
    "    curr_clipper_peaks = sorted(glob.glob(os.path.join(curr_output, curr_file_ext_dict['clipper_peaks'])))\n",
    "    \n",
    "    prev_inputnorm_peaks = sorted(glob.glob(os.path.join(prev_output, prev_file_ext_dict['inputnorm_peaks'])))\n",
    "    curr_inputnorm_peaks = sorted(glob.glob(os.path.join(curr_output, curr_file_ext_dict['inputnorm_peaks'])))\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        assert len(prev_clipper_peaks) == len(curr_clipper_peaks)\n",
    "    except AssertionError:\n",
    "        print(\"WARN: list of clipper files are different! {} vs {}\".format(len(prev_clipper_peaks), len(curr_clipper_peaks)))\n",
    "    \n",
    "    trimmed_files = pair_samples(prev_trimmed_fastqs, curr_trimmed_fastqs)\n",
    "    repeat_mapped_files = pair_samples(prev_repeat_alignments, curr_repeat_alignments)\n",
    "    genome_mapped_files = pair_samples(prev_genome_alignments, curr_genome_alignments)\n",
    "    clipper_files = pair_samples(prev_clipper_peaks, curr_clipper_peaks)\n",
    "    inputnormed_files = pair_samples(prev_inputnorm_peaks, curr_inputnorm_peaks)\n",
    "    \n",
    "    results = defaultdict(dict)\n",
    "    progress = tnrange(len(trimmed_files.keys()))\n",
    "    for sample_id in trimmed_files.keys():\n",
    "        prev = trimmed_files[sample_id]['prev']\n",
    "        curr = trimmed_files[sample_id]['curr']\n",
    "        trimmed_files_similarity, trimmed_files_dict = compare_trimmed_fastqs([prev, curr])\n",
    "        results[sample_id][\"Cutadapt\"] = trimmed_files_similarity\n",
    "        progress.update(1)\n",
    "    \n",
    "    \"\"\"\n",
    "    progress = tnrange(len(genome_mapped_files.keys()))\n",
    "    for sample_id in genome_mapped_files.keys():\n",
    "        prev = genome_mapped_files[sample_id]['prev']\n",
    "        curr = genome_mapped_files[sample_id]['curr']\n",
    "        genome_mapped_files_similarity, genome_mapped_files_dict = compare_bam_files([prev, curr])\n",
    "        results[sample_id][\"Genome\"] = genome_mapped_files_similarity\n",
    "        progress.update(1)\n",
    "    \"\"\"\n",
    "        \n",
    "    progress = tnrange(len(clipper_files.keys()))\n",
    "    for sample_id in clipper_files.keys():\n",
    "        prev = clipper_files[sample_id]['prev']\n",
    "        curr = clipper_files[sample_id]['curr']\n",
    "        clipper_peaks_similarity, clipper_peaks_dict = compare_bed_files([prev, curr])\n",
    "        results[sample_id][\"Clipper\"] = clipper_peaks_similarity\n",
    "        progress.update(1)\n",
    "        \n",
    "    return results\n",
    "    \n",
    "def pair_samples(prev_samples, curr_samples):\n",
    "    \"\"\"\n",
    "    Given two lists of files, group and return the pairs with matching prefixes.\n",
    "    \"\"\"\n",
    "    samples_dict = defaultdict(dict)\n",
    "    \n",
    "    for prev_sample in prev_samples:\n",
    "        samples_dict[get_prefix(prev_sample)]['prev'] = prev_sample\n",
    "    \n",
    "    for curr_sample in curr_samples:\n",
    "        samples_dict[get_prefix(curr_sample)]['curr'] = curr_sample\n",
    "        \n",
    "    return samples_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compare_outputs(\n",
    "    prev_output, prev_version, curr_output, curr_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-essential",
   "language": "python",
   "name": "python3-essential"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
