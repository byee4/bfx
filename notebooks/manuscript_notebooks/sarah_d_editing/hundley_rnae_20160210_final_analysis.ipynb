{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# packages needed to run this file:\n",
    "- install externally: bedtools 2.26.x\n",
    "- conda install pandas pybedtools matplotlib seaborn numpy tqdm gffutils\n",
    "### (if possible, install bedtools from source, or be aware of issue: https://github.com/arq5x/bedtools2/issues/471)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:52:31.544963Z",
     "start_time": "2017-05-30T15:52:29.919547Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bay001/anaconda2/envs/brian/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pybedtools as bt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import pybedtools\n",
    "import gffutils\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from collections import OrderedDict, defaultdict\n",
    "pd.set_option(\"display.max_rows\",500)\n",
    "gffhead = ['seqname','source','feature','start','end','score','strand','frame','attribute']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constants and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:52:31.554112Z",
     "start_time": "2017-05-30T15:52:31.547988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geneset = 'ws254'\n",
    "# insert the location of the latest version of bedtools ( to fix closest bug )\n",
    "BEDTOOLS = '/projects/ps-yeolab/software/bedtools-2.26.20170404/bedtools2/bin/bedtools'\n",
    "# original gff file contains a bunch of other annotations we don't want to use... let's just use wormbase.\n",
    "original_gff = '/projects/ps-yeolab3/bay001/annotations/c_elegans.PRJNA13758.WS254.annotations.gff3'\n",
    "# list of validated differentially expressed genes by qPCR\n",
    "VALIDATED = ['WBGene00007153','WBGene00000831','WBGene00022644','WBGene00002013','WBGene00009242']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify input directory and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:52:45.010674Z",
     "start_time": "2017-05-30T15:52:44.991967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory where the bam files are. Needed only for exon coverage calculations.\n",
    "bamdir = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/analysis/rnae_v6' \n",
    "# known edited genes (used to intersect called events with known edited genes)\n",
    "existing_transcripts = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/data/other_papers_called_transcripts.tab' \n",
    "# adr1 RIP targets (used to intersect edited genes with genes bound by adr1)\n",
    "adr_common_targets_list = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/analysis/ADR-1-RIP-targets-sent-to-Yeo-lab-May-2017.txt' \n",
    "# list of validated events\n",
    "validated_events_from_sarah = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/040517_supplemental_document_1_validated.events.csv' \n",
    "# go annotations downloaded from: http://geneontology.org/page/download-annotations\n",
    "go_association_file = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/gene_association.wb' \n",
    "# deseq2 differential expression results table.\n",
    "from_deseq2 = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/analysis/differential_expression/{}/diffexp.tsv'.format(\n",
    "    geneset\n",
    ") \n",
    "\n",
    "# filter settings\n",
    "min_confidence = 0.99\n",
    "# the endpoint of the pipeline\n",
    "common_suffix = '.sorted.rmdup.readfiltered.formatted.varfiltered.snpfiltered.ranked.conf' \n",
    "# where all the pipeline results are\n",
    "editing_calls_dir = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/analysis/editing_calls_v15_final/' \n",
    "wt_forward_conf = os.path.join(editing_calls_dir,'WT.fwd{}'.format(common_suffix))\n",
    "wt_reverse_conf = os.path.join(editing_calls_dir,'WT.rev{}'.format(common_suffix))\n",
    "ko_forward_conf = os.path.join(editing_calls_dir,'adr2ko.fwd{}'.format(common_suffix))\n",
    "ko_reverse_conf = os.path.join(editing_calls_dir,'adr2ko.rev{}'.format(common_suffix))\n",
    "\n",
    "editing_calls_dir = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/analysis/editing_test_against_aiden/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Specify output directory and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:50:11.158366Z",
     "start_time": "2017-05-30T15:50:11.136905Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_directory = '/projects/ps-yeolab3/bay001/hundley_rnae_20160210/analysis/editing_calls_v17_final/{}/'.format(geneset)\n",
    "known_snp_bed3file = os.path.join(output_directory,'known_snps.bed3')\n",
    "editing_annotation_file = os.path.join(output_directory,'wormbase.gff3')\n",
    "for_differential_expression = os.path.join(output_directory, '{}.saf'.format(geneset))\n",
    "all_output_regions_piechart = os.path.join(output_directory,'all_pie.svg')\n",
    "all_output_regions_annotations = os.path.join(output_directory,'annotations.txt')\n",
    "all_output_regions_wbgene_annotations = os.path.join(output_directory,'annotations_wbgene.txt')\n",
    "chemotaxis_locomotion_goterms = os.path.join(output_directory,'annotations_locomotion_and_chemotaxis.txt')\n",
    "validation_comparisons = os.path.join(output_directory,'validation_comparisons.txt')\n",
    "existing_transcripts_wbgene = os.path.join(output_directory, 'other_papers_called_transcripts.with_names.{}.tab'.format(geneset)) # known edited genes with wbgene names\n",
    "\n",
    "supplemental_doc1_edited_genes = os.path.join(output_directory,'supplemental_doc_1.txt')\n",
    "supplemental_doc1_sanger = os.path.join(output_directory,'supplemental_doc_1.sanger.txt')\n",
    "supplemental_doc1_genes = os.path.join(output_directory,'supplemental_doc_1.genes.txt')\n",
    "supplemental_doc1_novel = os.path.join(output_directory,'supplemental_doc_1.novel.txt')\n",
    "supplemental_doc1_locomotion = os.path.join(output_directory,'supplemental_doc_1.locomotion.txt')\n",
    "\n",
    "supplemental_doc2_upregulated_genes = os.path.join(output_directory,'supplemental_doc_2_upregulated_genes.txt')\n",
    "supplemental_doc2_downregulated_genes = os.path.join(output_directory,'supplemental_doc_2_downregulated_genes.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the annotation file for editing\n",
    "- re-format original file\n",
    "- Just use wormbase annotations\n",
    "- Re-name the 'I/II/III/etc. to chrI, chrII, chrIII, etc.'\n",
    "- Re-name the 'M' chromosome to 'MtDNA'\n",
    "- Pull out just the attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-30T15:52:05.869745Z",
     "start_time": "2017-05-30T15:50:12.794816Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_wormbase_and_format(original_gff, editing_annotation_file):\n",
    "    \"\"\"\n",
    "    pulls just the wormbase annotations\n",
    "    need to reformat the chromosome names from 'I, II' to 'chrI and chrII etc.'\n",
    "    \"\"\"\n",
    "    original_gff_df = pd.read_table(original_gff,names=gffhead, comment='#')\n",
    "    print(\"size of the original gff: {}\".format(original_gff_df.shape[0]))  # wow... lots of entries\n",
    "    wormbase = original_gff_df[original_gff_df['source']=='WormBase']\n",
    "    wormbase['seqname'] = 'chr'+wormbase['seqname'].replace('MtDNA','M')\n",
    "    wormbase[['start','end']] = wormbase[['start','end']].astype(int)  # change positions to INT from FLOAT\n",
    "    wormbase.sort_values(by=['seqname','start','end'], inplace=True)\n",
    "    wormbase.to_csv(editing_annotation_file, sep='\\t', index=None, header=None)\n",
    "\n",
    "    print(\"size of the wormbase gff: {}\".format(wormbase.shape[0]))  # better...\n",
    "    \n",
    "if not os.path.exists(editing_annotation_file):\n",
    "    make_wormbase_and_format(original_gff, editing_annotation_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the SAF file for differential expression\n",
    "- GFF3 isn't compatible with featureCounts, need to format into SAF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_saf_file(original_gff, saf_file):\n",
    "    original_gff_df = pd.read_table(original_gff,names=gffhead, comment='#')\n",
    "    print(\"size of the original gff: {}\".format(original_gff_df.shape[0]))  # wow... lots of entries\n",
    "    wormbase = original_gff_df[(original_gff_df['source']=='WormBase') & (original_gff_df['feature']=='gene')]\n",
    "    wormbase['seqname'] = 'chr'+wormbase['seqname'].replace('MtDNA','M')\n",
    "    wormbase[['start','end']] = wormbase[['start','end']].astype(int)  # change positions to INT from FLOAT\n",
    "    wormbase['GeneID'] = wormbase['attribute'].str.extract(\":([\\w\\d\\.]+)\")\n",
    "    wormbase = wormbase[['GeneID','seqname','start','end','strand']]\n",
    "    wormbase.to_csv(saf_file, sep='\\t', header=False, index=False)\n",
    "\n",
    "if not os.path.exists(for_differential_expression):\n",
    "    create_saf_file(original_gff, for_differential_expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create annotation file for known SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also parse this file while we have it to get the 'known SNP and point mutations'\n",
    "def make_snp_file(original_gff, known_snp_bed3file):\n",
    "    original_gff_df = pd.read_table(original_gff,names=gffhead)\n",
    "    snp = original_gff_df[\n",
    "        (original_gff_df['feature']=='SNP') | (original_gff_df['feature']=='point_mutation')\n",
    "    ]\n",
    "    snp['seqname_chr_formatted'] = 'chr' + snp['seqname']\n",
    "    snp['start_formatted'] = snp['start'].astype(int) - 1\n",
    "    snp['end_formatted'] = snp['end'].astype(int)\n",
    "    snp = snp[['seqname_chr_formatted','start_formatted','end_formatted']]\n",
    "    snp.drop_duplicates(inplace=True)\n",
    "    print('number of snps and single point mutations: {}'.format(snp.shape[0]))\n",
    "    snp.to_csv(known_snp_bed3file, sep='\\t', index=False, header=False)\n",
    "\n",
    "if not os.path.exists(known_snp_bed3file):\n",
    "    pass\n",
    "make_snp_file(original_gff, known_snp_bed3file)\n",
    "# original_gff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the editing pipeline\n",
    "- Use the 'known_snps' bed3 file\n",
    "\n",
    "# Run DESeq2 for differential expression\n",
    "- Use the SAF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses in this notebook:\n",
    "- filter confidence, \n",
    "- remove 'false positives' from KO\n",
    "- 'forward' and 'reverse' are designated based on editing site strand \n",
    "- annotation using bedtools and a gff3 file\n",
    "- intersection of editing sites and differential expression\n",
    "- intersection of editing sites and known edited genes from other publications\n",
    "- intersection of editing sites and experimentally validated editing sites (sanger sequencing)\n",
    "- intersection of editing sites and GO terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define intermediate files\n",
    "- this is where the intermediate bedfiles and things go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt_forward_bed = os.path.join(output_directory,'wt_forward.bed')\n",
    "wt_reverse_bed = os.path.join(output_directory,'wt_reverse.bed')\n",
    "ko_forward_bed = os.path.join(output_directory,'ko_forward.bed')\n",
    "ko_reverse_bed = os.path.join(output_directory,'ko_reverse.bed')\n",
    "\n",
    "wt_forward_sorted_bed = os.path.join(output_directory,'wt_forward.sorted.bed')\n",
    "wt_reverse_sorted_bed = os.path.join(output_directory,'wt_reverse.sorted.bed')\n",
    "ko_forward_sorted_bed = os.path.join(output_directory,'ko_forward.sorted.bed')\n",
    "ko_reverse_sorted_bed = os.path.join(output_directory,'ko_reverse.sorted.bed')\n",
    "\n",
    "editing_sites_conf_files = [wt_forward_conf, wt_reverse_conf, ko_forward_conf, ko_reverse_conf]\n",
    "editing_sites_bed_files = [wt_forward_bed, wt_reverse_bed, ko_forward_bed, ko_reverse_bed]\n",
    "editing_sites_sorted_bed_files = [wt_forward_sorted_bed, wt_reverse_sorted_bed, ko_forward_sorted_bed, ko_reverse_sorted_bed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create annotations for translating name/id/wbgene/feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = editing_annotation_file\n",
    "annotation_db_file = editing_annotation_file.replace('.gff3','.db')\n",
    "\n",
    "def build_db(annotation_file, annotation_db_file, force=False):\n",
    "    db = gffutils.create_db(\n",
    "        annotation_file, dbfn=annotation_db_file, force=force, # change to True if we need to create a new db\n",
    "        keep_order=True, merge_strategy='merge', sort_attribute_values=True\n",
    "    )\n",
    "\n",
    "if not os.path.exists(annotation_db_file):\n",
    "    print(\"db doesn't exist, building...\")\n",
    "    build_db(annotation_file, annotation_db_file)\n",
    "\n",
    "DATABASE = gffutils.FeatureDB(annotation_db_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define methods for converting between gene names/ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gene_id_to_name(db, attribute='Name'):\n",
    "    '''\n",
    "    takes a gene id and returns the first name associated (one-to-one)\n",
    "    '''\n",
    "    # db = gffutils.FeatureDB(db)\n",
    "    genes = db.features_of_type('gene')\n",
    "    gene_name_dict = {}\n",
    "    for gene in genes:\n",
    "        gene_id = gene.attributes['Name'][0] if type(gene.attributes['Name']) == list else gene.attributes['Name']\n",
    "        try:\n",
    "            gene_name_dict[gene_id] = gene.attributes['Alias'][0]\n",
    "        except KeyError:\n",
    "            print(\"Warning. Key not found for {}\".format(gene))\n",
    "    return gene_name_dict\n",
    "\n",
    "def gene_name_to_id(db, attribute='Name'):\n",
    "    '''\n",
    "    takes the name and returns a list of associated IDs (one-to-many)\n",
    "    '''\n",
    "    # db = gffutils.FeatureDB(db)\n",
    "    genes = db.features_of_type('gene')\n",
    "    gene_name_dict = defaultdict(list)\n",
    "    for gene in genes:\n",
    "        try:\n",
    "            gene_name_dict[gene.attributes['sequence_name'][0]].append(gene.attributes['Name'][0])\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            return 1\n",
    "            # print(\"Warning. Key not found for {}\".format(gene))\n",
    "    return gene_name_dict\n",
    "\n",
    "def gene_name_to_mrna(db, attribute='Name'):\n",
    "    '''\n",
    "    takes the name and returns a list of associated mRNA IDs (one-to-many)\n",
    "    '''\n",
    "    # db = gffutils.FeatureDB(db)\n",
    "    genes = db.features_of_type('mRNA')\n",
    "    gene_name_dict = defaultdict(list)\n",
    "    for gene in genes:\n",
    "        try:\n",
    "            gene_name_dict[gene.attributes['Name'][0]].append(gene.attributes['Parent'][0].replace('Gene:',''))\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            return 1\n",
    "            # print(\"Warning. Key not found for {}\".format(gene))\n",
    "    return gene_name_dict\n",
    "\n",
    "\n",
    "def gene_id_to_biotype(db):\n",
    "    '''\n",
    "    takes the id and returns a biotype (one-to-one)\n",
    "    '''\n",
    "    genes = db.features_of_type('gene')\n",
    "    gene_name_dict = {}\n",
    "    for gene in genes:\n",
    "        try:\n",
    "            gene_name_dict[gene.attributes['Name'][0]] = gene.attributes['biotype'][0]\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            return 1\n",
    "            # print(\"Warning. Key not found for {}\".format(gene))\n",
    "    return gene_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the database dictionaries \n",
    "id2name_dict = gene_id_to_name(DATABASE)\n",
    "name2id_dict = gene_name_to_id(DATABASE)\n",
    "name2mrna_dict = gene_name_to_mrna(DATABASE)\n",
    "id2biotype_dict = gene_id_to_biotype(DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define methods for assigning genic regions to editing sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_name(row, name2id_dict=name2id_dict):\n",
    "    \"\"\"\n",
    "    uses the dict to return id from name given our annotation dataframe\n",
    "    \"\"\"\n",
    "    if len(name2id_dict[row['attributes']]) > 0:\n",
    "        return name2id_dict[row['attributes']]\n",
    "    else:\n",
    "        return '-'\n",
    "\n",
    "def get_mrna_from_name(row, name2mrna_dict=name2mrna_dict):\n",
    "    \"\"\"\n",
    "    uses the dict to return mrna from name given our annotation dataframe\n",
    "    \"\"\"\n",
    "    if len(name2mrna_dict[row['attributes']]) > 0:\n",
    "        return name2mrna_dict[row['attributes']]\n",
    "    else:\n",
    "        return '-'\n",
    "\n",
    "def id_to_biotype(row, id2biotype_dict=id2biotype_dict):\n",
    "    \"\"\"\n",
    "    returns the biotype of a given row's region_id\n",
    "    \"\"\"\n",
    "    return id2biotype_dict[row['region_id']]\n",
    "\n",
    "def conf_to_bed(conf_file, output_bedfile, min_confidence):\n",
    "    \"\"\"\n",
    "    Converts a \"conf\" file (vcf format) into a filtered bedfile.\n",
    "    \n",
    "    conf_file : string - filename of the intermediate 'conf' file from editing pipeline output\n",
    "    output_bedfile : string - filename of the bed-formatted conf file\n",
    "    min_confidence : float - min confidence (ie. 0.99) to call an editing site\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Converting conf files to bedfiles: {}\".format(conf_file))\n",
    "    bedfile = open(output_bedfile,'w')\n",
    "    with open(conf_file,'r') as f:\n",
    "        for line in f:\n",
    "            strand = '.'\n",
    "            if not line.startswith('#'):\n",
    "                line = line.split('\\t')\n",
    "                if line[3] == 'A':  # if the editing pipeline called the ref allele as A, the it's +\n",
    "                    strand = '+'\n",
    "                elif line[3] == 'T':  # if ref allele is T, strand is -\n",
    "                    strand = '-'\n",
    "                else:\n",
    "                    print(\"WARN: Strand not correct\")\n",
    "                if float(line[5]) >= min_confidence:\n",
    "                    bedfile.write(\n",
    "                        \"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\n\".format(\n",
    "                            line[0],\n",
    "                            int(line[1])-1,\n",
    "                            line[1],\n",
    "                            int(float(line[7])*100),\n",
    "                            int(line[2]),\n",
    "                            strand\n",
    "                        )\n",
    "                    )\n",
    "    bedfile.close()\n",
    "    \n",
    "def is_intergenic(row):\n",
    "    \"\"\"\n",
    "    Returns a region if the distance is either:\n",
    "    1. within the region (0 bases away from feature)\n",
    "    2. within 2000 bp upstream a 5'UTR feature\n",
    "    3. withint 2000 bp downstream of a 3'UTR feature\n",
    "    Else returns 'intergenic' if neither are present.\n",
    "    \n",
    "    row : pandas row\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # bedtools closest found an intersection between a site and a feature\n",
    "        if(row['distance_from_region'] == 0 ): \n",
    "            return row['region_type'].replace('_',' ')\n",
    "        # bedtools closest found a feature downstream \n",
    "        elif(row['distance_from_region'] > 0 and \n",
    "             row['distance_from_region'] < 2000):\n",
    "            # downstream feature is a gene\n",
    "            if(('UTR' in row['region_type']) | \\\n",
    "               ('mRNA' in row['region_type']) | \\\n",
    "               ('CDS' in row['region_type'])\n",
    "              ):\n",
    "                return \"downstream from gene\"\n",
    "            else:\n",
    "                return \"downstream from ncRNA\"\n",
    "        # bedtools closest found a feature upstream \n",
    "        elif(row['distance_from_region'] < 0 and \n",
    "             row['distance_from_region'] > -2000): \n",
    "            # upstream feature is a gene\n",
    "            if(('UTR' in row['region_type']) | \\\n",
    "               ('mRNA' in row['region_type']) | \\\n",
    "               ('CDS' in row['region_type'])\n",
    "              ):\n",
    "                return \"upstream from gene\"\n",
    "            else:\n",
    "                return \"upstream from ncRNA\"\n",
    "        else:\n",
    "            return \"intergenic\"\n",
    "    except TypeError:\n",
    "        print(row)\n",
    "\n",
    "# region priority\n",
    "REGIONS = ['three prime UTR','five prime UTR',\n",
    "           'CDS','intron',\n",
    "           'mRNA','piRNA','ncRNA','tRNA','nc primary transcript',\n",
    "           'miRNA','snoRNA','pre miRNA','lincRNA','snRNA','antisense RNA',\n",
    "           'rRNA','miRNA primary transcript','scRNA', 'downstream from gene', \n",
    "           'upstream from gene', 'downstream from ncRNA', 'upstream from ncRNA', \n",
    "           'pseudogenic tRNA', 'pseudogenic transcript', 'exon']\n",
    "\n",
    "def priority(row):\n",
    "    \"\"\"\n",
    "    assign priority to the region given the regions defined\n",
    "    \n",
    "    row : pandas row\n",
    "    \n",
    "    return : int (0 being highest priority)\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(0,len(REGIONS)):\n",
    "        if row['region'] == REGIONS[i]:\n",
    "            return i\n",
    "    return len(REGIONS)\n",
    "\n",
    "\n",
    "def tostring(row):\n",
    "    \"\"\"\n",
    "    Concats the chrom:pos columns together. This will give each SNP a unique identifier.\n",
    "    \n",
    "    row : pandas row\n",
    "    \n",
    "    return : string\n",
    "    \"\"\"\n",
    "    return \"{}:{}\".format(row['chrom'],row['pos'])\n",
    "\n",
    "\n",
    "def get_closest(sites, genic_regions):\n",
    "    \"\"\"\n",
    "    for every gene, get the closest gene feature\n",
    "    \n",
    "    sites : pybedtools.BedTool\n",
    "    genic_regions : gff3 annotation file\n",
    "    \"\"\"\n",
    "    annotations = sites.closest(\n",
    "        genic_regions, \n",
    "        D='b',\n",
    "        s=True).to_dataframe(\n",
    "        names=[\n",
    "            'chrom','pos-1','pos','approx_edit_fraction','approx_coverage','strand',\n",
    "            'region_chrom','source','region_type','region_start','region_end','region_.',\n",
    "            'region_strand','.','attributes','distance_from_region'\n",
    "        ]\n",
    "    )\n",
    "    return annotations\n",
    "\n",
    "def get_closest_fix(sites_file, genic_region_file, bedtools=BEDTOOLS):\n",
    "    \"\"\"\n",
    "    Basically calls the dev version outside of this notebook. Drop-in replacement for \n",
    "    bedtools to use the dev. version because the current stable version is broken:\n",
    "    https://github.com/arq5x/bedtools2/issues/471\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tmp_output_file = 'closest.txt'\n",
    "    cmd = BEDTOOLS\n",
    "    cmd = cmd + ' closest'\n",
    "    cmd = cmd + ' -a {}'.format(sites_file)\n",
    "    cmd = cmd + ' -b {}'.format(genic_region_file)\n",
    "    cmd = cmd + ' -D b' + ' -s'\n",
    "    cmd = cmd + ' > {}'.format(tmp_output_file)\n",
    "    ! $cmd\n",
    "    df = read_closest_fix(tmp_output_file)\n",
    "    return df\n",
    "\n",
    "def read_closest_fix(f):\n",
    "    \"\"\"\n",
    "    Reads the external file output from get_closest_fix and return a dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.read_table(f, sep='\\t', names=[\n",
    "            'chrom','pos-1','pos','approx_edit_fraction','approx_coverage','strand',\n",
    "            'region_chrom','source','region_type','region_start','region_end','region_.',\n",
    "            'region_strand','.','attributes','distance_from_region'\n",
    "        ])\n",
    "    return df\n",
    "\n",
    "def assign_priority_and_remove_duplicate_assignments(annotations):\n",
    "    \"\"\"\n",
    "    takes the closest region and distance and determines whether it is 'close enough'\n",
    "    then reorders based on priority and makes sure only one region is called per site.\n",
    "    \n",
    "    annotations : pandas.DataFrame - dataframe of wt annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assign region and priority\n",
    "    # annotations['region_type'] = annotations.apply(id_to_biotype,axis=1)\n",
    "    annotations['region'] = annotations.apply(is_intergenic,axis=1)\n",
    "    annotations['priority'] = annotations.apply(priority,axis=1)\n",
    "\n",
    "    # Sort by ascending priority (1 is top)\n",
    "    annotations.sort_values(\n",
    "        by=['priority'],\n",
    "        inplace=True,\n",
    "        ascending=True\n",
    "    )\n",
    "    # Drop all but the first priority annotation\n",
    "    \n",
    "    annotations.drop_duplicates(\n",
    "        subset=[\n",
    "            'chrom','pos-1','pos','approx_coverage','approx_edit_fraction','strand'\n",
    "        ],\n",
    "        inplace=True,\n",
    "        keep='first',\n",
    "    )\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "\n",
    "def assign_false_positives(annotations):\n",
    "    \"\"\"\n",
    "    given ko_annotations, return the str representation \n",
    "    \n",
    "    annotations : pandas.DataFrame - dataframe containing KO annotations\n",
    "    \"\"\"\n",
    "    falsepositives = []\n",
    "    try:\n",
    "        falsepositives = annotations.apply(tostring,axis=1)\n",
    "        return list(set(falsepositives))\n",
    "    except ValueError:\n",
    "        print(\"no annotations found.\")\n",
    "        return []\n",
    "\n",
    "# plot the pie chart.\n",
    "def plot_pie(annotations, falsepositives, output_file):\n",
    "    \"\"\"\n",
    "    plots a pie chart\n",
    "    \n",
    "    annotations : pandas.DataFrame\n",
    "        table with all the wt annotations\n",
    "    falsepositives : pandas.Series\n",
    "        series with all of the 'stringified' false positive positions.\n",
    "        Only really used to print the number in the title.\n",
    "    output_file : string\n",
    "        output file of the final annotation\n",
    "        \n",
    "    \"\"\"\n",
    "    allsites = float(annotations['region'].value_counts().sum()) # total assigned regions\n",
    "\n",
    "    regions = OrderedDict(annotations['region'].value_counts())\n",
    "    labels = regions.keys()\n",
    "    nums = regions.values()\n",
    "    pcts = [100*(n / allsites) for n in nums]\n",
    "\n",
    "    colors = sns.color_palette(\"hls\", len(labels))\n",
    "\n",
    "    # Plot\n",
    "    patches, texts = plt.pie(\n",
    "        nums, colors=colors, shadow=False, startangle=140\n",
    "    )\n",
    "    \n",
    "    labels = ['{0} - {1} ({2:1.2f} %)'.format(i,j,k) for i,j,k in zip(labels, nums, pcts)]\n",
    "    \n",
    "    plt.axis('equal')\n",
    "    \n",
    "    plt.title(\n",
    "        'Editing Site Distribution by Region \\n Events: {} AFTER removing {} Adr2-'.format(\n",
    "            annotations.shape[0],\n",
    "            len(falsepositives)\n",
    "        ), y=1.08\n",
    "    )\n",
    "    \n",
    "    lgd = plt.legend(\n",
    "        patches, labels, loc='center right', bbox_to_anchor=(0.22, 0.5),\n",
    "        fontsize=10, \n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    # plt.subplots_adjust(top=0.7)\n",
    "    plt.savefig(output_file, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "def trim(df):\n",
    "    cleaned = df['attributes'].str.extract(\":([\\w\\d\\.]+)\")\n",
    "    \n",
    "    return cleaned\n",
    "    \n",
    "def format_annotations_nicely(annotations, falsepositives):\n",
    "    \"\"\"\n",
    "    re-name the existing GFF annotations to be more friendly. (\n",
    "    removes the stuff like Parent=Transcript: etc.).\n",
    "    \n",
    "    annotations : pandas.DataFrame\n",
    "        table with all the wt annotations\n",
    "    falsepositives : pandas.Series\n",
    "        series with all of the 'stringified' false positive positions\n",
    "    \"\"\"\n",
    "    \n",
    "    annotations['id'] = trim(annotations)\n",
    "    # chrompos serves as pivot for removing false positives\n",
    "    annotations['chrompos'] = annotations.apply(tostring,axis=1)\n",
    "    # remove the 'false positives'\n",
    "    print(\"Before KO removal: {}\".format(annotations.shape[0]))\n",
    "    annotations = annotations[annotations['chrompos'].isin(falsepositives)==False]\n",
    "    print(\"After KO removal: {}\".format(annotations.shape[0]))\n",
    "    # delete extraneous columns\n",
    "    del annotations['region_type'] # closest region, unneeded after assigning region. This also doesn't include 'downstream' and 'upstream' annotations.\n",
    "    del annotations['priority'] # don't need priority\n",
    "    del annotations['region_.'] # don't even use this field\n",
    "    del annotations['.'] # don't even use this field\n",
    "    del annotations['chrompos'] # don't need this field after removing KO false positives\n",
    "    del annotations['distance_from_region'] # comment this out if we want to see exactly where from a region the editing site lies.\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def sort_bed(bed_file, sorted_bed_file):\n",
    "    print(\"sorting {} > {}\".format(bed_file, sorted_bed_file))\n",
    "    bed_head = ['chrom','start','stop','name','score','strand']\n",
    "    bed = pd.read_table(bed_file, names=bed_head)\n",
    "    bed = pybedtools.BedTool.from_dataframe(bed).sort()\n",
    "    bed = bed.to_dataframe()\n",
    "    bed.to_csv(sorted_bed_file, sep='\\t', index=False, header=False)\n",
    "    return bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort, filter on confidence value and create sorted bedfiles\n",
    "for i in range(0, len(editing_sites_conf_files)):\n",
    "    conf_to_bed(\n",
    "        editing_sites_conf_files[i],\n",
    "        editing_sites_bed_files[i],\n",
    "        0.99\n",
    "    )\n",
    "    sort_bed(\n",
    "        editing_sites_bed_files[i],\n",
    "        editing_sites_sorted_bed_files[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# annotation of ADR2KO\n",
    "- get the closest region\n",
    "- get the string representation of the chrom:pos (these should now be unique identifiers). \n",
    "- list will be used as a final filter for sites called in WT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is from wormbase, above\n",
    "genes = bt.BedTool(editing_annotation_file)\n",
    "# create bedtools object\n",
    "ko_forward_rep = bt.BedTool(ko_forward_sorted_bed)\n",
    "ko_reverse_rep = bt.BedTool(ko_reverse_sorted_bed)\n",
    "# assign genic regions (we don't actually use this, but easier to import the resulting dataframe downstream)\n",
    "ko_forward_annotations = get_closest_fix(ko_forward_sorted_bed, editing_annotation_file)\n",
    "ko_reverse_annotations = get_closest_fix(ko_reverse_sorted_bed, editing_annotation_file)\n",
    "# returns a list of unique editing sites called in the adr2 knockouts\n",
    "forward_falsepositives = assign_false_positives(ko_forward_annotations)\n",
    "reverse_falsepositives = assign_false_positives(ko_reverse_annotations)\n",
    "\n",
    "print('number of forward false positives: {}'.format(len(forward_falsepositives)))\n",
    "print('number of reverse false positives: {}'.format(len(reverse_falsepositives)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add SNPs found in Adr2 to filter\n",
    "- we remove anything 100% edited in any sample, however this means we miss sites that are 100% edited in adr2- samples but not 100% edited in WT. \n",
    "- in this study, only one such site exists (chrM:8429 for min_confidence=0.99 and min_frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_headers = ['chrom','pos','num_reads','ref','alt','conf','post_pseudocount','pre_pseudocount','filter','info','format','baz']\n",
    "ko_fwd_conf_df = pd.read_table(ko_forward_conf, names=conf_headers)\n",
    "ko_rev_conf_df = pd.read_table(ko_reverse_conf, names=conf_headers)\n",
    "\n",
    "ko_fwd_snps = list(ko_fwd_conf_df[ko_fwd_conf_df['filter']==\"POSSIBLE_SNP\"].apply(tostring, axis=1))\n",
    "ko_rev_snps = list(ko_rev_conf_df[ko_rev_conf_df['filter']==\"POSSIBLE_SNP\"].apply(tostring, axis=1))\n",
    "\n",
    "for snp in ko_fwd_snps:\n",
    "    forward_falsepositives.append(snp)\n",
    "for snp in ko_rev_snps:\n",
    "    reverse_falsepositives.append(snp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation of WT\n",
    "- get closest region\n",
    "- assign priority to each region\n",
    "- format the annotation\n",
    "- remove the false positives based on the unique identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_forward_annotations = get_closest_fix(wt_forward_sorted_bed, editing_annotation_file)\n",
    "wt_reverse_annotations = get_closest_fix(wt_reverse_sorted_bed, editing_annotation_file)\n",
    "\n",
    "wt_forward_annotations = assign_priority_and_remove_duplicate_assignments(\n",
    "    wt_forward_annotations\n",
    ")\n",
    "wt_reverse_annotations = assign_priority_and_remove_duplicate_assignments(\n",
    "    wt_reverse_annotations\n",
    ")\n",
    "\n",
    "wt_forward_annotations = format_annotations_nicely(\n",
    "    wt_forward_annotations,\n",
    "    forward_falsepositives,\n",
    ")\n",
    "wt_reverse_annotations = format_annotations_nicely(\n",
    "    wt_reverse_annotations,\n",
    "    reverse_falsepositives,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge forward and reverse editing sites and plot pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations = pd.concat(\n",
    "    [wt_forward_annotations, wt_reverse_annotations]\n",
    ")\n",
    "all_falsepositives = reverse_falsepositives + forward_falsepositives\n",
    "plot_pie(all_annotations, all_falsepositives, all_output_regions_piechart)\n",
    "all_annotations.to_csv(\n",
    "    all_output_regions_annotations,\n",
    "    sep='\\t',\n",
    "    index=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the false positives and look to see if they make sense..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forward_falsepositives, reverse_falsepositives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add wbgenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wbgene(row):\n",
    "    \"\"\"\n",
    "    Return the wb gene id based on the id in the annotation file\n",
    "    Some IDs were not caught because of discrepancies, so these need to be manually curated.\n",
    "    \"\"\"\n",
    "    \n",
    "    # exception: the true annotation is R10E8.1a, but the actual associated wbgene id is for R10E8.1\n",
    "    if row['id'][:-1] == 'R10E8.1':\n",
    "        return 'WBGene00011207'\n",
    "    # exception: the true annotation is Y73B3A.3b, but the actual associated wbgene id is for Y73B3A.3\n",
    "    if row['id'][:-1] == 'Y73B3A.3':\n",
    "        return 'WBGene00022205'\n",
    "    # exception: the true annotation is T14G10.2, but the actual associated wbgene id is for Y73B3A.3\n",
    "    if row['id'] == 'T14G10.2e':\n",
    "        return 'WBGene00004254'\n",
    "    if row['id'] == 'W06H8.8f':\n",
    "        return 'WBGene00006436'\n",
    "    if row['id'].startswith('WBGene'):\n",
    "        return row['id']\n",
    "    idlist = name2id_dict[row['id']]\n",
    "    if len(idlist) == 0:\n",
    "        idlist = name2mrna_dict[row['id']]\n",
    "        \n",
    "    idlist_string = ','.join(idlist)\n",
    "    \n",
    "    if len(idlist) == 0:\n",
    "        if row['region'] == 'intergenic':\n",
    "            return row['id']\n",
    "    return idlist_string\n",
    "\n",
    "def add_name(row, col='wbgene'):\n",
    "    \"\"\"\n",
    "    Given an ID, return the name using the database file above.\n",
    "    \"\"\"\n",
    "    if row[col] != '' and row[col] in id2name_dict.keys():\n",
    "        name = id2name_dict[row[col]]\n",
    "        return name\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations['wbgene'] = all_annotations.apply(get_wbgene,axis=1)\n",
    "all_annotations['gene'] = all_annotations.apply(add_name,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations.to_csv(\n",
    "    all_output_regions_wbgene_annotations,\n",
    "    sep='\\t',\n",
    "    index=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give wbgene names to other discovered transcripts\n",
    "- transform existing editing sites (from other papers) into their wbgene name, to compare to our calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_from_sarah = pd.read_table(\n",
    "    existing_transcripts,\n",
    "    names=['transcript1','name1','transcript2','name2','transcript3','name3']\n",
    ")\n",
    "genes_from_sarah.fillna('.',inplace=True)\n",
    "genes_from_sarah.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2id(row, col='transcript1'):\n",
    "    if row[col] == '.':\n",
    "        return '.'\n",
    "    else:\n",
    "        ret = name2id_dict[row[col]]\n",
    "    if len(ret) == 0:\n",
    "        return '.'\n",
    "    else:\n",
    "        return ret[0]\n",
    "    \n",
    "def add_name(row, col='wbgene1'):\n",
    "    if row[col] == '.':\n",
    "        return '.'\n",
    "    else:\n",
    "        ret = id2name_dict[row[col]]\n",
    "    if len(ret) == 0:\n",
    "        return '.'\n",
    "    else:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = tnrange(6)\n",
    "genes_from_sarah['wbgene1'] = genes_from_sarah.apply(name2id, axis=1, args=['transcript1'])\n",
    "progress.update(1)\n",
    "genes_from_sarah['wbgene2'] = genes_from_sarah.apply(name2id, axis=1, args=['transcript2'])\n",
    "progress.update(1)\n",
    "genes_from_sarah['wbgene3'] = genes_from_sarah.apply(name2id, axis=1, args=['transcript3'])\n",
    "progress.update(1)\n",
    "genes_from_sarah['name1'] = genes_from_sarah.apply(add_name, axis=1, args=['wbgene1'])\n",
    "progress.update(1)\n",
    "genes_from_sarah['name2'] = genes_from_sarah.apply(add_name, axis=1, args=['wbgene2'])\n",
    "progress.update(1)\n",
    "genes_from_sarah['name3'] = genes_from_sarah.apply(add_name, axis=1, args=['wbgene3'])\n",
    "progress.update(1)\n",
    "genes_from_sarah.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of already discovered edited genes and compare against ours\n",
    "- get unique set of gene names known to be edited from previous manuscripts\n",
    "- print number of edited genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = list(set(genes_from_sarah['wbgene1']))\n",
    "g2 = list(set(genes_from_sarah['wbgene2']))\n",
    "g3 = list(set(genes_from_sarah['wbgene3']))\n",
    "\n",
    "g_all = []\n",
    "g_all.append(g1)\n",
    "g_all.append(g2)\n",
    "g_all.append(g3)\n",
    "g = [item for sublist in g_all for item in sublist]\n",
    "g = set(g)\n",
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_no_intergenic = all_annotations[all_annotations['region']!='intergenic']\n",
    "\n",
    "our_n = set(all_annotations_no_intergenic['gene'])\n",
    "our_g = set(all_annotations_no_intergenic['wbgene'])\n",
    "from matplotlib_venn import venn2, venn3\n",
    "venn2([our_g,g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(our_g - g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(supplemental_doc1_genes, 'w') as f:\n",
    "    f.write(\"Genes Identified as Edited\\n\")\n",
    "    f.write(\"Wormbase ID\\tGene Name\\n\")\n",
    "    for gene in our_g:\n",
    "        f.write('{}\\t{}\\n'.format(gene,id2name_dict[gene]))\n",
    "with open(supplemental_doc1_novel, 'w') as f:\n",
    "    f.write(\"Novel Genes Identified as Edited\\n\")\n",
    "    f.write(\"Wormbase ID\\tGene Name\\n\")\n",
    "    for gene in (our_g - g):\n",
    "        f.write('{}\\t{}\\n'.format(gene,id2name_dict[gene]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_from_sarah[\n",
    "    ['transcript1','wbgene1','name1','transcript2','wbgene2','name2','transcript3','wbgene3','name3']\n",
    "].to_csv(\n",
    "    existing_transcripts_wbgene,\n",
    "    sep='\\t',\n",
    "    index=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check to see how many genes were edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "all_annotations_no_intergenic = all_annotations[all_annotations['region']!='intergenic']\n",
    "all_annotations_no_intergenic['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of edited genes: {}\".format(len(set(all_annotations_no_intergenic['gene']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see that we've assigned all genic regions. Some may be missed due to inexact matching of IDs in database\n",
    "all_annotations_no_intergenic[all_annotations_no_intergenic['gene']=='']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check against validated sanger editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this was the original validation table - we now need to compare the current (0.0.3 pipeline) set with the original (0.0.2) results. \n",
    "validated_sites = pd.read_table(\n",
    "    validated_events_from_sarah,\n",
    "    sep='\\t'\n",
    ")\n",
    "validated_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append current annotations to validated dataframe and compare\n",
    "- should be mostly identical\n",
    "- differences should come only from changes in pipeline filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations_edit_frac = all_annotations[['chrom','pos','approx_edit_fraction']]\n",
    "all_annotations_edit_frac.columns = ['Chromosome', 'Editing site position', '0.0.3 % edited (RNA seq)']\n",
    "validated_df = pd.merge(\n",
    "    all_annotations_edit_frac, \n",
    "    validated_sites, \n",
    "    how='right', \n",
    "    # on=['Chromosome','Editing site position']\n",
    "    left_on=['Chromosome', 'Editing site position'], \n",
    "    right_on=['Chromosome','Editing site position']\n",
    ")\n",
    "validated_df.to_csv(validation_comparisons,sep='\\t', index=None)\n",
    "validated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare editing sites discovered by validation (Sanger) that were not picked up by our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = validated_df.fillna('NONE')\n",
    "print(\"Number of sites not captured by pipeline but discovered to be edited via sanger: {}\".format(vdf[\n",
    "    (vdf['Identified in Sanger Sequencing']=='Yes') &\n",
    "    (vdf['0.0.3 % edited (RNA seq)']=='NONE')\n",
    "].shape[0]))\n",
    "print(\"Number of sites captured by pipeline AND discovered to be edited via sanger: {}\".format(vdf[\n",
    "    (vdf['Identified in Sanger Sequencing']=='Yes') &\n",
    "    (vdf['0.0.3 % edited (RNA seq)']!='NONE')\n",
    "].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sites captured by the pipeline against Sanger validations\n",
    "validated_df.dropna(subset=['0.0.3 % edited (RNA seq)'])['Identified in Sanger Sequencing'].value_counts()\n",
    "validated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_table = validated_df[\n",
    "    ['Gene','Chromosome','Editing site position','0.0.3 % edited (RNA seq)',\n",
    "     'Identified in Sanger Sequencing','Predicted by RNA-Seq Pipeline'\n",
    "    ]\n",
    "]\n",
    "verification_table['Editing site position'] = verification_table['Editing site position'].astype(int)\n",
    "verification_table.columns = [\n",
    "    'Gene','Chromosome','Editing site position','0.0.3 % edited (RNA seq)','Identified in Sanger Sequencing','Predicted by RNA-Seq pipeline'\n",
    "]\n",
    "verification_table.to_csv(supplemental_doc1_sanger, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check differential expression output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseq2_df = pd.read_table(from_deseq2)\n",
    "deseq2_df.sort_values(by='padj',inplace=True)\n",
    "l2fc_threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Number of upregulated genes (with respect to WT): {}\".format(\n",
    "        deseq2_df[(deseq2_df['log2FoldChange']>=l2fc_threshold)].shape[0]\n",
    "    )\n",
    ")#  & (deseq2_df['padj']<0.05)].shape\n",
    "print(\n",
    "    \"Number of downregulated genes (with respect to WT): {}\".format(\n",
    "        deseq2_df[(deseq2_df['log2FoldChange']<=-l2fc_threshold)].shape[0]\n",
    "    )\n",
    ")#  & (deseq2_df['padj']<0.05)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check against qPCR Differential Expression validated results:\n",
    "- These should not change no matter what annotation we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(VALIDATED)):\n",
    "    print(id2name_dict[VALIDATED[i]], pd.DataFrame(deseq2_df.ix[VALIDATED[i]]).T) # clec-41 (should be downregulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(deseq2_df.ix['WBGene00000831']).T # ctl-2 (should be downregulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(deseq2_df.ix['WBGene00022644']).T # dod-19 (should be downregulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(deseq2_df.ix['WBGene00002013']).T # hsp-12.6 (should be upregulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(deseq2_df.ix['WBGene00009242']).T # sre-6 (should be upregulated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the number of genes DE that were edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upregulated = deseq2_df[(deseq2_df['log2FoldChange']>=1)] # this was criteria for filtering\n",
    "downregulated = deseq2_df[(deseq2_df['log2FoldChange']<=-1)] # this was criteria for filtering\n",
    "upregulated_genes = set(list(upregulated.index))\n",
    "downregulated_genes = set(list(downregulated.index))\n",
    "edited_genes = set(list(all_annotations_no_intergenic['wbgene']))\n",
    "print(\"DOWNREGULATED + EDITED GENES\")\n",
    "for gene in downregulated_genes.intersection(edited_genes):\n",
    "    print(gene, id2name_dict[gene])\n",
    "print(\"UPREGULATED + EDITED GENES\")\n",
    "for gene in upregulated_genes.intersection(edited_genes):\n",
    "    print(gene, id2name_dict[gene])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr1_list = pd.read_table(\n",
    "    adr_common_targets_list,\n",
    ")\n",
    "ADR1_LIST = list(adr1_list['Common targets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check number of genes involved in chemotaxis that are edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bound_by_adr1(row, adr1_list=ADR1_LIST):\n",
    "    if row['gene'] in adr1_list:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "GO_TERMS = [\n",
    "    'GO:0040011',\n",
    "    'GO:0043058',\n",
    "    'GO:0040012',\n",
    "    'GO:0006935',\n",
    "    'GO:0040017',\n",
    "    'GO:0043059',\n",
    "    'GO:0050919'\n",
    "] # these are GO terms that are associated with chemotaxis and locomotion\n",
    "go = go_association_file\n",
    "go_df = pd.read_table(go, comment='!', sep='\\t', names=range(0,17))\n",
    "go_df = go_df[go_df[4].isin(GO_TERMS)]\n",
    "go_df_genes = list(set(go_df[1]))\n",
    "genes_in_go = all_annotations[\n",
    "    (all_annotations['wbgene'].isin(go_df_genes)) & (all_annotations['region']!='intergenic')\n",
    "]\n",
    "genes_in_go = genes_in_go[['wbgene','gene']]\n",
    "genes_in_go.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_in_go['Bound by Adr-1'] = genes_in_go.apply(bound_by_adr1, axis=1)\n",
    "genes_in_go.columns = ['Wormbase ID','Gene','Bound by Adr-1']\n",
    "genes_in_go.to_csv(supplemental_doc1_locomotion, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations[\n",
    "    (all_annotations['wbgene'].isin(go_df_genes)) & (all_annotations['region']!='intergenic')\n",
    "].to_csv(chemotaxis_locomotion_goterms,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at individual editing site calls for our gene of interest (clec-41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = 'clec-41'\n",
    "print(\"Number of editing sites found in gene {}: {}\".format(\n",
    "        gene, all_annotations[all_annotations['gene']==gene].shape[0]\n",
    "    )\n",
    "     )\n",
    "all_annotations[all_annotations['gene']==gene]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate supplemental table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_s1 = all_annotations[['chrom','pos','approx_edit_fraction','approx_coverage','region','wbgene','gene']]\n",
    "table_s1.columns = ['Chromosome','Position','% Edit','Coverage','Region','Wormbase ID','Gene Name']\n",
    "table_s1.to_csv(supplemental_doc1_edited_genes, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate supplemental table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deseq2_df = pd.read_table(\n",
    "    from_deseq2, names=['Wormbase ID','baseMean','log2FoldChange','lfcSE','stat','pvalue','adjusted p-value'],skiprows=1\n",
    ")\n",
    "\n",
    "del deseq2_df['pvalue']\n",
    "del deseq2_df['stat']\n",
    "del deseq2_df['lfcSE']\n",
    "\n",
    "l2fc_threshold = 1\n",
    "\n",
    "def fold_ratio(row):\n",
    "    return math.pow(2, row['log2FoldChange'])\n",
    "\n",
    "def add_gene_name(row):\n",
    "    return id2name_dict[row['Wormbase ID']]\n",
    "\n",
    "def is_validated(row, validated_list=VALIDATED):\n",
    "    if row['Wormbase ID'] in validated_list:\n",
    "        return 'Verified'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def is_edited(row, edited_list=list(all_annotations_no_intergenic['wbgene'])):\n",
    "    if row['Wormbase ID'] in edited_list:\n",
    "        return 'Edited'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def create_supplemental_doc2(dysregulated_genes):\n",
    "\n",
    "    dysregulated_genes['Fold Ratio'] = dysregulated_genes.apply(fold_ratio, axis=1)\n",
    "    dysregulated_genes['Gene'] = dysregulated_genes.apply(add_gene_name, axis=1)\n",
    "    dysregulated_genes['adjusted p-value'].fillna(1, inplace=True)\n",
    "    dysregulated_genes['Verified'] = dysregulated_genes.apply(is_validated, axis=1)\n",
    "    dysregulated_genes['Edited'] = dysregulated_genes.apply(is_edited, axis=1)\n",
    "    return dysregulated_genes\n",
    "\n",
    "upregulated_genes = deseq2_df[(deseq2_df['log2FoldChange']>=l2fc_threshold)]\n",
    "upregulated_genes = create_supplemental_doc2(upregulated_genes)\n",
    "upregulated_genes[['Gene','Wormbase ID','baseMean','Fold Ratio','adjusted p-value','Verified','Edited']].to_csv(\n",
    "    supplemental_doc2_upregulated_genes, sep='\\t', index=False\n",
    ")\n",
    "\n",
    "downregulated_genes = deseq2_df[(deseq2_df['log2FoldChange']<=-l2fc_threshold)]\n",
    "downregulated_genes = create_supplemental_doc2(downregulated_genes)\n",
    "downregulated_genes[['Gene','Wormbase ID','baseMean','Fold Ratio','adjusted p-value','Verified','Edited']].to_csv(\n",
    "    supplemental_doc2_downregulated_genes, sep='\\t', index=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
